{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MandirMarg = pd.read_csv(r'C:\\Users\\Shalini\\Documents\\b.csv')\n",
    "PunjabiBagh = pd.read_csv(r'C:\\Users\\Shalini\\Documents\\c.csv')\n",
    "RKPuram = pd.read_csv(r'C:\\Users\\Shalini\\Documents\\d.csv')\n",
    "combined = MandirMarg.append(PunjabiBagh)\n",
    "df = combined.append(RKPuram)\n",
    "col_type='num'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (col_type == 'num'):\n",
    "    predictors = df.select_dtypes(exclude=['object'])\n",
    "elif (col_type == 'no_num'):\n",
    "    predictors = df.select_dtypes(include=['object'])\n",
    "elif (col_type == 'all'):\n",
    "    predictors = df\n",
    "else :\n",
    "    print('Error : choose a type (num, no_num, all)')\n",
    "cols_with_no_nans = []\n",
    "for col in predictors.columns:\n",
    "        if not df[col].isnull().any():\n",
    "            cols_with_no_nans.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()\n",
    "k=[]\n",
    "k=df.PM.tolist()\n",
    "#k = [s for s in k if s.isdigit()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df=df.dropna()\n",
    "df=df[df.Latitude>0]\n",
    "df=df[df.Longitude>0]\n",
    "df=df[df.PM10>0]\n",
    "df=df[df.SO2>0]\n",
    "df=df[df.NO2>0]\n",
    "df=df[df.BENZENE>0]\n",
    "df=df[df.CO>0]\n",
    "df=df[df.O3>0]\n",
    "df=df[df.NH3>0]\n",
    "df=df[df.Month>0]\n",
    "df=df[df.Temp>0]\n",
    "df=df[df.Precipitation>0]\n",
    "df=df[df.Windspeed>0]\n",
    "df=df[df.Humidity>0]\n",
    "df=df[df.PM>0]\n",
    "df=df[df.Year>0]\n",
    "df.hist(figsize = (10,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df.PM\n",
    "df.drop(['PM'],axis = 1 , inplace = True)\n",
    "target.dropna()\n",
    "l=[]\n",
    "l=df.values.tolist()\n",
    "tl=[]\n",
    "tl=target.values.tolist()\n",
    "#from numpy import array\n",
    "#la = array(l)\n",
    "#tla = array(tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "C_mat = df.corr()\n",
    "fig = plt.figure(figsize = (15,15))\n",
    "sb.heatmap(C_mat, vmax = .8, square = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Latitude', 'Longitude', 'PM10', 'SO2', 'NO2', 'BENZENE', 'CO', 'O3', 'NH3', 'Month', 'Temp', 'Precipitation', 'Windspeed', 'Humidity', 'Year']\n"
     ]
    }
   ],
   "source": [
    "colNames=['Latitude','Longitude','PM10','SO2','NO2','BENZENE','CO','O3','NH3','Month','Temp','Precipitation','Windspeed','Humidity','Year']\n",
    "print(colNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 15 columns before encoding categorical features\n",
      "There are 15 columns after encoding categorical features\n"
     ]
    }
   ],
   "source": [
    "print('There were {} columns before encoding categorical features'.format(df.shape[1]))\n",
    "for col in colNames:\n",
    "        if( df[col].dtype == np.dtype('object')):\n",
    "            dummies = pd.get_dummies(df[col],prefix=col)\n",
    "            df = pd.concat([df,dummies],axis=1)\n",
    "            df.drop([col],axis = 1 , inplace=True)\n",
    "print('There are {} columns after encoding categorical features'.format(df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Shalini\\Documents\\temp2\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "NN_model.add(Dense(128, kernel_initializer='normal',input_dim = df.shape[1], activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               2048      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 166,913\n",
      "Trainable params: 166,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 126 samples, validate on 32 samples\n",
      "Epoch 1/500\n",
      "126/126 [==============================] - 0s 231us/step - loss: 27.0043 - mean_absolute_error: 27.0043 - val_loss: 36.3692 - val_mean_absolute_error: 36.3692\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 10.29650\n",
      "Epoch 2/500\n",
      "126/126 [==============================] - 0s 162us/step - loss: 25.8417 - mean_absolute_error: 25.8417 - val_loss: 24.5077 - val_mean_absolute_error: 24.5077\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 10.29650\n",
      "Epoch 3/500\n",
      "126/126 [==============================] - 0s 167us/step - loss: 26.0072 - mean_absolute_error: 26.0072 - val_loss: 12.1200 - val_mean_absolute_error: 12.1200\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 10.29650\n",
      "Epoch 4/500\n",
      "126/126 [==============================] - 0s 244us/step - loss: 26.4746 - mean_absolute_error: 26.4746 - val_loss: 33.7416 - val_mean_absolute_error: 33.7416\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 10.29650\n",
      "Epoch 5/500\n",
      "126/126 [==============================] - 0s 497us/step - loss: 26.2639 - mean_absolute_error: 26.2639 - val_loss: 25.0150 - val_mean_absolute_error: 25.0150\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 10.29650\n",
      "Epoch 6/500\n",
      "126/126 [==============================] - 0s 431us/step - loss: 24.5935 - mean_absolute_error: 24.5935 - val_loss: 17.4666 - val_mean_absolute_error: 17.4666\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 10.29650\n",
      "Epoch 7/500\n",
      "126/126 [==============================] - 0s 423us/step - loss: 24.8223 - mean_absolute_error: 24.8223 - val_loss: 33.5760 - val_mean_absolute_error: 33.5760\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 10.29650\n",
      "Epoch 8/500\n",
      "126/126 [==============================] - 0s 221us/step - loss: 24.5755 - mean_absolute_error: 24.5755 - val_loss: 13.6097 - val_mean_absolute_error: 13.6097\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 10.29650\n",
      "Epoch 9/500\n",
      "126/126 [==============================] - 0s 185us/step - loss: 23.8132 - mean_absolute_error: 23.8132 - val_loss: 29.4046 - val_mean_absolute_error: 29.4046\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 10.29650\n",
      "Epoch 10/500\n",
      "126/126 [==============================] - 0s 328us/step - loss: 23.6942 - mean_absolute_error: 23.6942 - val_loss: 23.4201 - val_mean_absolute_error: 23.4201\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 10.29650\n",
      "Epoch 11/500\n",
      "126/126 [==============================] - 0s 315us/step - loss: 24.0222 - mean_absolute_error: 24.0222 - val_loss: 15.4608 - val_mean_absolute_error: 15.4608\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 10.29650\n",
      "Epoch 12/500\n",
      "126/126 [==============================] - 0s 377us/step - loss: 24.3737 - mean_absolute_error: 24.3737 - val_loss: 30.6416 - val_mean_absolute_error: 30.6416\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 10.29650\n",
      "Epoch 13/500\n",
      "126/126 [==============================] - 0s 397us/step - loss: 25.2132 - mean_absolute_error: 25.2132 - val_loss: 33.1745 - val_mean_absolute_error: 33.1745\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 10.29650\n",
      "Epoch 14/500\n",
      "126/126 [==============================] - 0s 253us/step - loss: 25.2802 - mean_absolute_error: 25.2802 - val_loss: 11.0987 - val_mean_absolute_error: 11.0987\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 10.29650\n",
      "Epoch 15/500\n",
      "126/126 [==============================] - 0s 202us/step - loss: 25.8550 - mean_absolute_error: 25.8550 - val_loss: 28.3093 - val_mean_absolute_error: 28.3093\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 10.29650\n",
      "Epoch 16/500\n",
      "126/126 [==============================] - 0s 169us/step - loss: 26.4129 - mean_absolute_error: 26.4129 - val_loss: 35.0234 - val_mean_absolute_error: 35.0234\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 10.29650\n",
      "Epoch 17/500\n",
      "126/126 [==============================] - 0s 163us/step - loss: 28.1885 - mean_absolute_error: 28.1885 - val_loss: 12.6270 - val_mean_absolute_error: 12.6270\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 10.29650\n",
      "Epoch 18/500\n",
      "126/126 [==============================] - 0s 150us/step - loss: 30.9005 - mean_absolute_error: 30.9005 - val_loss: 45.9320 - val_mean_absolute_error: 45.9320\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 10.29650\n",
      "Epoch 19/500\n",
      "126/126 [==============================] - 0s 147us/step - loss: 29.7040 - mean_absolute_error: 29.7040 - val_loss: 17.5760 - val_mean_absolute_error: 17.5760\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 10.29650\n",
      "Epoch 20/500\n",
      "126/126 [==============================] - 0s 159us/step - loss: 25.1860 - mean_absolute_error: 25.1860 - val_loss: 18.9659 - val_mean_absolute_error: 18.9659\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 10.29650\n",
      "Epoch 21/500\n",
      "126/126 [==============================] - 0s 137us/step - loss: 25.8184 - mean_absolute_error: 25.8184 - val_loss: 47.5739 - val_mean_absolute_error: 47.5739\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 10.29650\n",
      "Epoch 22/500\n",
      "126/126 [==============================] - 0s 182us/step - loss: 31.4787 - mean_absolute_error: 31.4787 - val_loss: 11.9257 - val_mean_absolute_error: 11.9257\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 10.29650\n",
      "Epoch 23/500\n",
      "126/126 [==============================] - 0s 249us/step - loss: 25.3438 - mean_absolute_error: 25.3438 - val_loss: 39.3108 - val_mean_absolute_error: 39.3108\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 10.29650\n",
      "Epoch 24/500\n",
      "126/126 [==============================] - 0s 146us/step - loss: 25.1783 - mean_absolute_error: 25.1783 - val_loss: 18.2256 - val_mean_absolute_error: 18.2256\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 10.29650\n",
      "Epoch 25/500\n",
      "126/126 [==============================] - 0s 152us/step - loss: 24.0657 - mean_absolute_error: 24.0657 - val_loss: 23.8407 - val_mean_absolute_error: 23.8407\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 10.29650\n",
      "Epoch 26/500\n",
      "126/126 [==============================] - 0s 307us/step - loss: 24.3337 - mean_absolute_error: 24.3337 - val_loss: 26.6292 - val_mean_absolute_error: 26.6292\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 10.29650\n",
      "Epoch 27/500\n",
      "126/126 [==============================] - 0s 293us/step - loss: 23.2800 - mean_absolute_error: 23.2800 - val_loss: 24.7613 - val_mean_absolute_error: 24.7613\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 10.29650\n",
      "Epoch 28/500\n",
      "126/126 [==============================] - 0s 217us/step - loss: 24.2200 - mean_absolute_error: 24.2200 - val_loss: 16.9468 - val_mean_absolute_error: 16.9468\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 10.29650\n",
      "Epoch 29/500\n",
      "126/126 [==============================] - 0s 231us/step - loss: 24.6530 - mean_absolute_error: 24.6530 - val_loss: 30.0528 - val_mean_absolute_error: 30.0528\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 10.29650\n",
      "Epoch 30/500\n",
      "126/126 [==============================] - 0s 167us/step - loss: 25.3982 - mean_absolute_error: 25.3982 - val_loss: 31.9746 - val_mean_absolute_error: 31.9746\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 10.29650\n",
      "Epoch 31/500\n",
      "126/126 [==============================] - 0s 169us/step - loss: 24.0859 - mean_absolute_error: 24.0859 - val_loss: 17.3858 - val_mean_absolute_error: 17.3858\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 10.29650\n",
      "Epoch 32/500\n",
      "126/126 [==============================] - 0s 129us/step - loss: 24.8154 - mean_absolute_error: 24.8154 - val_loss: 20.1319 - val_mean_absolute_error: 20.1319\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 10.29650\n",
      "Epoch 33/500\n",
      "126/126 [==============================] - 0s 277us/step - loss: 23.5165 - mean_absolute_error: 23.5165 - val_loss: 23.7362 - val_mean_absolute_error: 23.7362\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 10.29650\n",
      "Epoch 34/500\n",
      "126/126 [==============================] - 0s 162us/step - loss: 23.2416 - mean_absolute_error: 23.2416 - val_loss: 22.9299 - val_mean_absolute_error: 22.9299\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 10.29650\n",
      "Epoch 35/500\n",
      "126/126 [==============================] - 0s 134us/step - loss: 23.1788 - mean_absolute_error: 23.1788 - val_loss: 21.6819 - val_mean_absolute_error: 21.6819\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 10.29650\n",
      "Epoch 36/500\n",
      "126/126 [==============================] - 0s 121us/step - loss: 23.6039 - mean_absolute_error: 23.6039 - val_loss: 36.9817 - val_mean_absolute_error: 36.9817\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 10.29650\n",
      "Epoch 37/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 0s 239us/step - loss: 25.0307 - mean_absolute_error: 25.0307 - val_loss: 11.2101 - val_mean_absolute_error: 11.2101\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 10.29650\n",
      "Epoch 38/500\n",
      "126/126 [==============================] - 0s 209us/step - loss: 26.1786 - mean_absolute_error: 26.1786 - val_loss: 27.2854 - val_mean_absolute_error: 27.2854\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 10.29650\n",
      "Epoch 39/500\n",
      "126/126 [==============================] - 0s 214us/step - loss: 23.4210 - mean_absolute_error: 23.4210 - val_loss: 23.3712 - val_mean_absolute_error: 23.3712\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 10.29650\n",
      "Epoch 40/500\n",
      "126/126 [==============================] - 0s 330us/step - loss: 23.7827 - mean_absolute_error: 23.7827 - val_loss: 31.8277 - val_mean_absolute_error: 31.8277\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 10.29650\n",
      "Epoch 41/500\n",
      "126/126 [==============================] - 0s 211us/step - loss: 24.3355 - mean_absolute_error: 24.3355 - val_loss: 20.0535 - val_mean_absolute_error: 20.0535\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 10.29650\n",
      "Epoch 42/500\n",
      "126/126 [==============================] - 0s 272us/step - loss: 23.4843 - mean_absolute_error: 23.4843 - val_loss: 22.8047 - val_mean_absolute_error: 22.8047\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 10.29650\n",
      "Epoch 43/500\n",
      "126/126 [==============================] - 0s 214us/step - loss: 24.0015 - mean_absolute_error: 24.0015 - val_loss: 32.6455 - val_mean_absolute_error: 32.6455\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 10.29650\n",
      "Epoch 44/500\n",
      "126/126 [==============================] - 0s 221us/step - loss: 24.1348 - mean_absolute_error: 24.1348 - val_loss: 11.7692 - val_mean_absolute_error: 11.7692\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 10.29650\n",
      "Epoch 45/500\n",
      "126/126 [==============================] - 0s 212us/step - loss: 29.5685 - mean_absolute_error: 29.5685 - val_loss: 47.6327 - val_mean_absolute_error: 47.6327\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 10.29650\n",
      "Epoch 46/500\n",
      "126/126 [==============================] - 0s 201us/step - loss: 30.7272 - mean_absolute_error: 30.7272 - val_loss: 14.1827 - val_mean_absolute_error: 14.1827\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 10.29650\n",
      "Epoch 47/500\n",
      "126/126 [==============================] - 0s 253us/step - loss: 24.5966 - mean_absolute_error: 24.5966 - val_loss: 23.5520 - val_mean_absolute_error: 23.5520\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 10.29650\n",
      "Epoch 48/500\n",
      "126/126 [==============================] - 0s 213us/step - loss: 23.7343 - mean_absolute_error: 23.7343 - val_loss: 23.0112 - val_mean_absolute_error: 23.0112\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 10.29650\n",
      "Epoch 49/500\n",
      "126/126 [==============================] - 0s 169us/step - loss: 23.5417 - mean_absolute_error: 23.5417 - val_loss: 17.9332 - val_mean_absolute_error: 17.9332\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 10.29650\n",
      "Epoch 50/500\n",
      "126/126 [==============================] - 0s 242us/step - loss: 24.1488 - mean_absolute_error: 24.1488 - val_loss: 22.4216 - val_mean_absolute_error: 22.4216\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 10.29650\n",
      "Epoch 51/500\n",
      "126/126 [==============================] - 0s 184us/step - loss: 23.4797 - mean_absolute_error: 23.4797 - val_loss: 27.2339 - val_mean_absolute_error: 27.2339\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 10.29650\n",
      "Epoch 52/500\n",
      "126/126 [==============================] - 0s 242us/step - loss: 23.3657 - mean_absolute_error: 23.3657 - val_loss: 30.9213 - val_mean_absolute_error: 30.9213\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 10.29650\n",
      "Epoch 53/500\n",
      "126/126 [==============================] - 0s 193us/step - loss: 24.4695 - mean_absolute_error: 24.4695 - val_loss: 17.7483 - val_mean_absolute_error: 17.7483\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 10.29650\n",
      "Epoch 54/500\n",
      "126/126 [==============================] - 0s 183us/step - loss: 22.5518 - mean_absolute_error: 22.5518 - val_loss: 25.5980 - val_mean_absolute_error: 25.5980\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 10.29650\n",
      "Epoch 55/500\n",
      "126/126 [==============================] - 0s 226us/step - loss: 23.3895 - mean_absolute_error: 23.3895 - val_loss: 14.8361 - val_mean_absolute_error: 14.8361\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 10.29650\n",
      "Epoch 56/500\n",
      "126/126 [==============================] - 0s 311us/step - loss: 23.6519 - mean_absolute_error: 23.6519 - val_loss: 27.4640 - val_mean_absolute_error: 27.4640\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 10.29650\n",
      "Epoch 57/500\n",
      "126/126 [==============================] - 0s 309us/step - loss: 22.7629 - mean_absolute_error: 22.7629 - val_loss: 21.2152 - val_mean_absolute_error: 21.2152\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 10.29650\n",
      "Epoch 58/500\n",
      "126/126 [==============================] - 0s 210us/step - loss: 22.7643 - mean_absolute_error: 22.7643 - val_loss: 30.3375 - val_mean_absolute_error: 30.3375\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 10.29650\n",
      "Epoch 59/500\n",
      "126/126 [==============================] - 0s 223us/step - loss: 23.4806 - mean_absolute_error: 23.4806 - val_loss: 11.5679 - val_mean_absolute_error: 11.5679\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 10.29650\n",
      "Epoch 60/500\n",
      "126/126 [==============================] - 0s 250us/step - loss: 24.8330 - mean_absolute_error: 24.8330 - val_loss: 40.2831 - val_mean_absolute_error: 40.2831\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 10.29650\n",
      "Epoch 61/500\n",
      "126/126 [==============================] - 0s 193us/step - loss: 26.9503 - mean_absolute_error: 26.9503 - val_loss: 12.8334 - val_mean_absolute_error: 12.8334\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 10.29650\n",
      "Epoch 62/500\n",
      "126/126 [==============================] - 0s 198us/step - loss: 25.9183 - mean_absolute_error: 25.9183 - val_loss: 31.8459 - val_mean_absolute_error: 31.8459\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 10.29650\n",
      "Epoch 63/500\n",
      "126/126 [==============================] - 0s 320us/step - loss: 27.0555 - mean_absolute_error: 27.0555 - val_loss: 38.0970 - val_mean_absolute_error: 38.0970\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 10.29650\n",
      "Epoch 64/500\n",
      "126/126 [==============================] - 0s 213us/step - loss: 29.0685 - mean_absolute_error: 29.0685 - val_loss: 10.8216 - val_mean_absolute_error: 10.8216\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 10.29650\n",
      "Epoch 65/500\n",
      "126/126 [==============================] - 0s 223us/step - loss: 26.2671 - mean_absolute_error: 26.2671 - val_loss: 53.8220 - val_mean_absolute_error: 53.8220\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 10.29650\n",
      "Epoch 66/500\n",
      "126/126 [==============================] - 0s 177us/step - loss: 27.9991 - mean_absolute_error: 27.9991 - val_loss: 10.6670 - val_mean_absolute_error: 10.6670\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 10.29650\n",
      "Epoch 67/500\n",
      "126/126 [==============================] - 0s 209us/step - loss: 25.3593 - mean_absolute_error: 25.3593 - val_loss: 37.0101 - val_mean_absolute_error: 37.0101\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 10.29650\n",
      "Epoch 68/500\n",
      "126/126 [==============================] - 0s 332us/step - loss: 24.5550 - mean_absolute_error: 24.5550 - val_loss: 20.5535 - val_mean_absolute_error: 20.5535\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 10.29650\n",
      "Epoch 69/500\n",
      "126/126 [==============================] - 0s 126us/step - loss: 23.5037 - mean_absolute_error: 23.5037 - val_loss: 19.3223 - val_mean_absolute_error: 19.3223\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 10.29650\n",
      "Epoch 70/500\n",
      "126/126 [==============================] - 0s 170us/step - loss: 24.8581 - mean_absolute_error: 24.8581 - val_loss: 36.8535 - val_mean_absolute_error: 36.8535\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 10.29650\n",
      "Epoch 71/500\n",
      "126/126 [==============================] - 0s 166us/step - loss: 23.9734 - mean_absolute_error: 23.9734 - val_loss: 17.1245 - val_mean_absolute_error: 17.1245\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 10.29650\n",
      "Epoch 72/500\n",
      "126/126 [==============================] - 0s 185us/step - loss: 23.2062 - mean_absolute_error: 23.2062 - val_loss: 35.6074 - val_mean_absolute_error: 35.6074\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 10.29650\n",
      "Epoch 73/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 0s 180us/step - loss: 25.2633 - mean_absolute_error: 25.2633 - val_loss: 12.5670 - val_mean_absolute_error: 12.5670\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 10.29650\n",
      "Epoch 74/500\n",
      "126/126 [==============================] - 0s 204us/step - loss: 24.6701 - mean_absolute_error: 24.6701 - val_loss: 32.5352 - val_mean_absolute_error: 32.5352\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 10.29650\n",
      "Epoch 75/500\n",
      "126/126 [==============================] - ETA: 0s - loss: 20.1386 - mean_absolute_error: 20.138 - 0s 151us/step - loss: 24.7989 - mean_absolute_error: 24.7989 - val_loss: 24.3553 - val_mean_absolute_error: 24.3553\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 10.29650\n",
      "Epoch 76/500\n",
      "126/126 [==============================] - 0s 210us/step - loss: 26.6143 - mean_absolute_error: 26.6143 - val_loss: 10.5380 - val_mean_absolute_error: 10.5380\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 10.29650\n",
      "Epoch 77/500\n",
      "126/126 [==============================] - 0s 228us/step - loss: 27.5919 - mean_absolute_error: 27.5919 - val_loss: 47.6575 - val_mean_absolute_error: 47.6575\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 10.29650\n",
      "Epoch 78/500\n",
      "126/126 [==============================] - 0s 301us/step - loss: 29.0256 - mean_absolute_error: 29.0256 - val_loss: 11.1950 - val_mean_absolute_error: 11.1950\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 10.29650\n",
      "Epoch 79/500\n",
      "126/126 [==============================] - 0s 275us/step - loss: 24.9277 - mean_absolute_error: 24.9277 - val_loss: 43.9996 - val_mean_absolute_error: 43.9996\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 10.29650\n",
      "Epoch 80/500\n",
      "126/126 [==============================] - 0s 259us/step - loss: 29.5201 - mean_absolute_error: 29.5201 - val_loss: 13.7882 - val_mean_absolute_error: 13.7882\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 10.29650\n",
      "Epoch 81/500\n",
      "126/126 [==============================] - 0s 184us/step - loss: 25.8292 - mean_absolute_error: 25.8292 - val_loss: 23.5221 - val_mean_absolute_error: 23.5221\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 10.29650\n",
      "Epoch 82/500\n",
      "126/126 [==============================] - ETA: 0s - loss: 15.3985 - mean_absolute_error: 15.398 - 0s 253us/step - loss: 24.4141 - mean_absolute_error: 24.4141 - val_loss: 27.9822 - val_mean_absolute_error: 27.9822\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 10.29650\n",
      "Epoch 83/500\n",
      "126/126 [==============================] - 0s 128us/step - loss: 24.2705 - mean_absolute_error: 24.2705 - val_loss: 15.9644 - val_mean_absolute_error: 15.9644\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 10.29650\n",
      "Epoch 84/500\n",
      "126/126 [==============================] - 0s 256us/step - loss: 24.3902 - mean_absolute_error: 24.3902 - val_loss: 29.8555 - val_mean_absolute_error: 29.8555\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 10.29650\n",
      "Epoch 85/500\n",
      "126/126 [==============================] - 0s 233us/step - loss: 22.5930 - mean_absolute_error: 22.5930 - val_loss: 14.0427 - val_mean_absolute_error: 14.0427\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 10.29650\n",
      "Epoch 86/500\n",
      "126/126 [==============================] - 0s 212us/step - loss: 23.5230 - mean_absolute_error: 23.5230 - val_loss: 33.1691 - val_mean_absolute_error: 33.1691\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 10.29650\n",
      "Epoch 87/500\n",
      "126/126 [==============================] - 0s 238us/step - loss: 23.5406 - mean_absolute_error: 23.5406 - val_loss: 18.9321 - val_mean_absolute_error: 18.9321\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 10.29650\n",
      "Epoch 88/500\n",
      "126/126 [==============================] - 0s 151us/step - loss: 23.6815 - mean_absolute_error: 23.6815 - val_loss: 27.4748 - val_mean_absolute_error: 27.4748\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 10.29650\n",
      "Epoch 89/500\n",
      "126/126 [==============================] - 0s 217us/step - loss: 24.4606 - mean_absolute_error: 24.4606 - val_loss: 26.1465 - val_mean_absolute_error: 26.1465\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 10.29650\n",
      "Epoch 90/500\n",
      "126/126 [==============================] - 0s 221us/step - loss: 24.0449 - mean_absolute_error: 24.0449 - val_loss: 18.3860 - val_mean_absolute_error: 18.3860\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 10.29650\n",
      "Epoch 91/500\n",
      "126/126 [==============================] - 0s 242us/step - loss: 22.9036 - mean_absolute_error: 22.9036 - val_loss: 36.9026 - val_mean_absolute_error: 36.9026\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 10.29650\n",
      "Epoch 92/500\n",
      "126/126 [==============================] - 0s 217us/step - loss: 23.6078 - mean_absolute_error: 23.6078 - val_loss: 16.3109 - val_mean_absolute_error: 16.3109\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 10.29650\n",
      "Epoch 93/500\n",
      "126/126 [==============================] - 0s 233us/step - loss: 23.4263 - mean_absolute_error: 23.4263 - val_loss: 35.8422 - val_mean_absolute_error: 35.8422\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 10.29650\n",
      "Epoch 94/500\n",
      "126/126 [==============================] - 0s 244us/step - loss: 26.1579 - mean_absolute_error: 26.1579 - val_loss: 11.3165 - val_mean_absolute_error: 11.3165\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 10.29650\n",
      "Epoch 95/500\n",
      "126/126 [==============================] - 0s 285us/step - loss: 24.6811 - mean_absolute_error: 24.6811 - val_loss: 47.5788 - val_mean_absolute_error: 47.5788\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 10.29650\n",
      "Epoch 96/500\n",
      "126/126 [==============================] - 0s 199us/step - loss: 26.3294 - mean_absolute_error: 26.3294 - val_loss: 10.5453 - val_mean_absolute_error: 10.5453\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 10.29650\n",
      "Epoch 97/500\n",
      "126/126 [==============================] - 0s 285us/step - loss: 27.4695 - mean_absolute_error: 27.4695 - val_loss: 42.3056 - val_mean_absolute_error: 42.3056\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 10.29650\n",
      "Epoch 98/500\n",
      "126/126 [==============================] - 0s 150us/step - loss: 24.5858 - mean_absolute_error: 24.5858 - val_loss: 14.7218 - val_mean_absolute_error: 14.7218\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 10.29650\n",
      "Epoch 99/500\n",
      "126/126 [==============================] - 0s 274us/step - loss: 26.1590 - mean_absolute_error: 26.1590 - val_loss: 21.5322 - val_mean_absolute_error: 21.5322\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 10.29650\n",
      "Epoch 100/500\n",
      "126/126 [==============================] - 0s 193us/step - loss: 24.0282 - mean_absolute_error: 24.0282 - val_loss: 25.2174 - val_mean_absolute_error: 25.2174\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 10.29650\n",
      "Epoch 101/500\n",
      "126/126 [==============================] - 0s 183us/step - loss: 24.5814 - mean_absolute_error: 24.5814 - val_loss: 17.4216 - val_mean_absolute_error: 17.4216\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 10.29650\n",
      "Epoch 102/500\n",
      "126/126 [==============================] - 0s 197us/step - loss: 23.6730 - mean_absolute_error: 23.6730 - val_loss: 37.6688 - val_mean_absolute_error: 37.6688\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 10.29650\n",
      "Epoch 103/500\n",
      "126/126 [==============================] - 0s 256us/step - loss: 26.2610 - mean_absolute_error: 26.2610 - val_loss: 11.1156 - val_mean_absolute_error: 11.1156\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 10.29650\n",
      "Epoch 104/500\n",
      "126/126 [==============================] - 0s 232us/step - loss: 27.6528 - mean_absolute_error: 27.6528 - val_loss: 43.4114 - val_mean_absolute_error: 43.4114\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 10.29650\n",
      "Epoch 105/500\n",
      "126/126 [==============================] - 0s 149us/step - loss: 28.7314 - mean_absolute_error: 28.7314 - val_loss: 10.8193 - val_mean_absolute_error: 10.8193\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 10.29650\n",
      "Epoch 106/500\n",
      "126/126 [==============================] - 0s 154us/step - loss: 27.9036 - mean_absolute_error: 27.9036 - val_loss: 26.8004 - val_mean_absolute_error: 26.8004\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 10.29650\n",
      "Epoch 107/500\n",
      "126/126 [==============================] - 0s 199us/step - loss: 26.1842 - mean_absolute_error: 26.1842 - val_loss: 20.8335 - val_mean_absolute_error: 20.8335\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 10.29650\n",
      "Epoch 108/500\n",
      "126/126 [==============================] - 0s 214us/step - loss: 24.6679 - mean_absolute_error: 24.6679 - val_loss: 15.1569 - val_mean_absolute_error: 15.1569\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 10.29650\n",
      "Epoch 109/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 0s 175us/step - loss: 24.4662 - mean_absolute_error: 24.4662 - val_loss: 26.1415 - val_mean_absolute_error: 26.1415\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 10.29650\n",
      "Epoch 110/500\n",
      "126/126 [==============================] - 0s 170us/step - loss: 24.3655 - mean_absolute_error: 24.3655 - val_loss: 29.9401 - val_mean_absolute_error: 29.9401\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 10.29650\n",
      "Epoch 111/500\n",
      "126/126 [==============================] - 0s 178us/step - loss: 23.7784 - mean_absolute_error: 23.7784 - val_loss: 10.3691 - val_mean_absolute_error: 10.3691\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 10.29650\n",
      "Epoch 112/500\n",
      "126/126 [==============================] - 0s 243us/step - loss: 26.0173 - mean_absolute_error: 26.0173 - val_loss: 44.6341 - val_mean_absolute_error: 44.6341\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 10.29650\n",
      "Epoch 113/500\n",
      "126/126 [==============================] - 0s 283us/step - loss: 25.1514 - mean_absolute_error: 25.1514 - val_loss: 10.5999 - val_mean_absolute_error: 10.5999\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 10.29650\n",
      "Epoch 114/500\n",
      "126/126 [==============================] - 0s 204us/step - loss: 23.9928 - mean_absolute_error: 23.9928 - val_loss: 29.9670 - val_mean_absolute_error: 29.9670\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 10.29650\n",
      "Epoch 115/500\n",
      "126/126 [==============================] - 0s 198us/step - loss: 23.5100 - mean_absolute_error: 23.5100 - val_loss: 22.4627 - val_mean_absolute_error: 22.4627\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 10.29650\n",
      "Epoch 116/500\n",
      "126/126 [==============================] - 0s 218us/step - loss: 22.7492 - mean_absolute_error: 22.7492 - val_loss: 20.3876 - val_mean_absolute_error: 20.3876\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 10.29650\n",
      "Epoch 117/500\n",
      "126/126 [==============================] - 0s 283us/step - loss: 22.3785 - mean_absolute_error: 22.3785 - val_loss: 26.7679 - val_mean_absolute_error: 26.7679\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 10.29650\n",
      "Epoch 118/500\n",
      "126/126 [==============================] - 0s 230us/step - loss: 22.4143 - mean_absolute_error: 22.4143 - val_loss: 18.5064 - val_mean_absolute_error: 18.5064\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 10.29650\n",
      "Epoch 119/500\n",
      "126/126 [==============================] - 0s 254us/step - loss: 22.6192 - mean_absolute_error: 22.6192 - val_loss: 26.9310 - val_mean_absolute_error: 26.9310\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 10.29650\n",
      "Epoch 120/500\n",
      "126/126 [==============================] - 0s 194us/step - loss: 22.6838 - mean_absolute_error: 22.6838 - val_loss: 22.9375 - val_mean_absolute_error: 22.9375\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 10.29650\n",
      "Epoch 121/500\n",
      "126/126 [==============================] - 0s 224us/step - loss: 24.0415 - mean_absolute_error: 24.0415 - val_loss: 17.2928 - val_mean_absolute_error: 17.2928\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 10.29650\n",
      "Epoch 122/500\n",
      "126/126 [==============================] - 0s 130us/step - loss: 23.7571 - mean_absolute_error: 23.7571 - val_loss: 40.1480 - val_mean_absolute_error: 40.1480\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 10.29650\n",
      "Epoch 123/500\n",
      "126/126 [==============================] - 0s 251us/step - loss: 25.8064 - mean_absolute_error: 25.8064 - val_loss: 13.0854 - val_mean_absolute_error: 13.0854\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 10.29650\n",
      "Epoch 124/500\n",
      "126/126 [==============================] - 0s 204us/step - loss: 24.4527 - mean_absolute_error: 24.4527 - val_loss: 30.1127 - val_mean_absolute_error: 30.1127\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 10.29650\n",
      "Epoch 125/500\n",
      "126/126 [==============================] - 0s 216us/step - loss: 22.5303 - mean_absolute_error: 22.5303 - val_loss: 14.4832 - val_mean_absolute_error: 14.4832\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 10.29650\n",
      "Epoch 126/500\n",
      "126/126 [==============================] - 0s 258us/step - loss: 22.7104 - mean_absolute_error: 22.7104 - val_loss: 27.1840 - val_mean_absolute_error: 27.1840\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 10.29650\n",
      "Epoch 127/500\n",
      "126/126 [==============================] - 0s 187us/step - loss: 22.3061 - mean_absolute_error: 22.3061 - val_loss: 20.1354 - val_mean_absolute_error: 20.1354\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 10.29650\n",
      "Epoch 128/500\n",
      "126/126 [==============================] - 0s 175us/step - loss: 22.4081 - mean_absolute_error: 22.4081 - val_loss: 27.7779 - val_mean_absolute_error: 27.7779\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 10.29650\n",
      "Epoch 129/500\n",
      "126/126 [==============================] - 0s 175us/step - loss: 23.3055 - mean_absolute_error: 23.3055 - val_loss: 21.5345 - val_mean_absolute_error: 21.5345\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 10.29650\n",
      "Epoch 130/500\n",
      "126/126 [==============================] - 0s 186us/step - loss: 23.3843 - mean_absolute_error: 23.3843 - val_loss: 18.4250 - val_mean_absolute_error: 18.4250\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 10.29650\n",
      "Epoch 131/500\n",
      "126/126 [==============================] - 0s 274us/step - loss: 23.1504 - mean_absolute_error: 23.1504 - val_loss: 30.6062 - val_mean_absolute_error: 30.6062\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 10.29650\n",
      "Epoch 132/500\n",
      "126/126 [==============================] - 0s 200us/step - loss: 22.9120 - mean_absolute_error: 22.9120 - val_loss: 14.8254 - val_mean_absolute_error: 14.8254\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 10.29650\n",
      "Epoch 133/500\n",
      "126/126 [==============================] - ETA: 0s - loss: 15.9125 - mean_absolute_error: 15.912 - 0s 166us/step - loss: 23.7994 - mean_absolute_error: 23.7994 - val_loss: 27.5408 - val_mean_absolute_error: 27.5408\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 10.29650\n",
      "Epoch 134/500\n",
      "126/126 [==============================] - 0s 219us/step - loss: 22.4754 - mean_absolute_error: 22.4754 - val_loss: 20.5087 - val_mean_absolute_error: 20.5087\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 10.29650\n",
      "Epoch 135/500\n",
      "126/126 [==============================] - 0s 290us/step - loss: 22.4841 - mean_absolute_error: 22.4841 - val_loss: 18.8528 - val_mean_absolute_error: 18.8528\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 10.29650\n",
      "Epoch 136/500\n",
      "126/126 [==============================] - 0s 255us/step - loss: 22.9645 - mean_absolute_error: 22.9645 - val_loss: 35.6644 - val_mean_absolute_error: 35.6644\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 10.29650\n",
      "Epoch 137/500\n",
      "126/126 [==============================] - 0s 229us/step - loss: 24.9901 - mean_absolute_error: 24.9901 - val_loss: 10.6688 - val_mean_absolute_error: 10.6688\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 10.29650\n",
      "Epoch 138/500\n",
      "126/126 [==============================] - 0s 155us/step - loss: 26.2110 - mean_absolute_error: 26.2110 - val_loss: 36.6763 - val_mean_absolute_error: 36.6763\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 10.29650\n",
      "Epoch 139/500\n",
      "126/126 [==============================] - 0s 200us/step - loss: 22.6537 - mean_absolute_error: 22.6537 - val_loss: 16.2069 - val_mean_absolute_error: 16.2069\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 10.29650\n",
      "Epoch 140/500\n",
      "126/126 [==============================] - 0s 121us/step - loss: 23.1843 - mean_absolute_error: 23.1843 - val_loss: 23.4381 - val_mean_absolute_error: 23.4381\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 10.29650\n",
      "Epoch 141/500\n",
      "126/126 [==============================] - 0s 167us/step - loss: 22.3791 - mean_absolute_error: 22.3791 - val_loss: 25.3536 - val_mean_absolute_error: 25.3536\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 10.29650\n",
      "Epoch 142/500\n",
      "126/126 [==============================] - 0s 187us/step - loss: 22.3649 - mean_absolute_error: 22.3649 - val_loss: 26.0994 - val_mean_absolute_error: 26.0994\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 10.29650\n",
      "Epoch 143/500\n",
      "126/126 [==============================] - 0s 244us/step - loss: 23.4438 - mean_absolute_error: 23.4438 - val_loss: 18.2655 - val_mean_absolute_error: 18.2655\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 10.29650\n",
      "Epoch 144/500\n",
      "126/126 [==============================] - 0s 163us/step - loss: 23.2387 - mean_absolute_error: 23.2387 - val_loss: 22.3638 - val_mean_absolute_error: 22.3638\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 10.29650\n",
      "Epoch 145/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 0s 182us/step - loss: 23.4067 - mean_absolute_error: 23.4067 - val_loss: 30.5258 - val_mean_absolute_error: 30.5258\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 10.29650\n",
      "Epoch 146/500\n",
      "126/126 [==============================] - 0s 171us/step - loss: 25.5228 - mean_absolute_error: 25.5228 - val_loss: 13.2020 - val_mean_absolute_error: 13.2020\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 10.29650\n",
      "Epoch 147/500\n",
      "126/126 [==============================] - 0s 215us/step - loss: 23.5136 - mean_absolute_error: 23.5136 - val_loss: 36.0565 - val_mean_absolute_error: 36.0565\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 10.29650\n",
      "Epoch 148/500\n",
      "126/126 [==============================] - 0s 201us/step - loss: 24.0973 - mean_absolute_error: 24.0973 - val_loss: 17.2654 - val_mean_absolute_error: 17.2654\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 10.29650\n",
      "Epoch 149/500\n",
      "126/126 [==============================] - 0s 196us/step - loss: 22.1972 - mean_absolute_error: 22.1972 - val_loss: 23.7336 - val_mean_absolute_error: 23.7336\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 10.29650\n",
      "Epoch 150/500\n",
      "126/126 [==============================] - 0s 191us/step - loss: 22.6430 - mean_absolute_error: 22.6430 - val_loss: 21.7255 - val_mean_absolute_error: 21.7255\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 10.29650\n",
      "Epoch 151/500\n",
      "126/126 [==============================] - 0s 239us/step - loss: 22.5990 - mean_absolute_error: 22.5990 - val_loss: 17.0026 - val_mean_absolute_error: 17.0026\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 10.29650\n",
      "Epoch 152/500\n",
      "126/126 [==============================] - 0s 245us/step - loss: 23.2086 - mean_absolute_error: 23.2086 - val_loss: 24.1426 - val_mean_absolute_error: 24.1426\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 10.29650\n",
      "Epoch 153/500\n",
      "126/126 [==============================] - 0s 243us/step - loss: 23.7586 - mean_absolute_error: 23.7586 - val_loss: 30.3822 - val_mean_absolute_error: 30.3822\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 10.29650\n",
      "Epoch 154/500\n",
      "126/126 [==============================] - 0s 234us/step - loss: 24.3492 - mean_absolute_error: 24.3492 - val_loss: 17.0993 - val_mean_absolute_error: 17.0993\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 10.29650\n",
      "Epoch 155/500\n",
      "126/126 [==============================] - 0s 166us/step - loss: 24.1446 - mean_absolute_error: 24.1446 - val_loss: 36.8445 - val_mean_absolute_error: 36.8445\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 10.29650\n",
      "Epoch 156/500\n",
      "126/126 [==============================] - 0s 278us/step - loss: 24.0248 - mean_absolute_error: 24.0248 - val_loss: 18.6560 - val_mean_absolute_error: 18.6560\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 10.29650\n",
      "Epoch 157/500\n",
      "126/126 [==============================] - 0s 255us/step - loss: 22.2533 - mean_absolute_error: 22.2533 - val_loss: 31.1237 - val_mean_absolute_error: 31.1237\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 10.29650\n",
      "Epoch 158/500\n",
      "126/126 [==============================] - 0s 219us/step - loss: 23.1879 - mean_absolute_error: 23.1879 - val_loss: 17.4354 - val_mean_absolute_error: 17.4354\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 10.29650\n",
      "Epoch 159/500\n",
      "126/126 [==============================] - 0s 204us/step - loss: 22.8765 - mean_absolute_error: 22.8765 - val_loss: 23.3590 - val_mean_absolute_error: 23.3590\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 10.29650\n",
      "Epoch 160/500\n",
      "126/126 [==============================] - 0s 256us/step - loss: 22.6003 - mean_absolute_error: 22.6003 - val_loss: 23.0056 - val_mean_absolute_error: 23.0056\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 10.29650\n",
      "Epoch 161/500\n",
      "126/126 [==============================] - 0s 311us/step - loss: 23.0538 - mean_absolute_error: 23.0538 - val_loss: 27.9739 - val_mean_absolute_error: 27.9739\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 10.29650\n",
      "Epoch 162/500\n",
      "126/126 [==============================] - 0s 267us/step - loss: 22.2314 - mean_absolute_error: 22.2314 - val_loss: 18.6197 - val_mean_absolute_error: 18.6197\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 10.29650\n",
      "Epoch 163/500\n",
      "126/126 [==============================] - 0s 224us/step - loss: 22.2829 - mean_absolute_error: 22.2829 - val_loss: 25.4860 - val_mean_absolute_error: 25.4860\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 10.29650\n",
      "Epoch 164/500\n",
      "126/126 [==============================] - 0s 216us/step - loss: 21.9622 - mean_absolute_error: 21.9622 - val_loss: 27.8296 - val_mean_absolute_error: 27.8296\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 10.29650\n",
      "Epoch 165/500\n",
      "126/126 [==============================] - 0s 221us/step - loss: 22.1951 - mean_absolute_error: 22.1951 - val_loss: 24.8811 - val_mean_absolute_error: 24.8811\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 10.29650\n",
      "Epoch 166/500\n",
      "126/126 [==============================] - 0s 251us/step - loss: 22.1574 - mean_absolute_error: 22.1574 - val_loss: 17.1028 - val_mean_absolute_error: 17.1028\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 10.29650\n",
      "Epoch 167/500\n",
      "126/126 [==============================] - 0s 265us/step - loss: 21.7906 - mean_absolute_error: 21.7906 - val_loss: 31.0541 - val_mean_absolute_error: 31.0541\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 10.29650\n",
      "Epoch 168/500\n",
      "126/126 [==============================] - 0s 189us/step - loss: 23.5557 - mean_absolute_error: 23.5557 - val_loss: 20.5021 - val_mean_absolute_error: 20.5021\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 10.29650\n",
      "Epoch 169/500\n",
      "126/126 [==============================] - 0s 246us/step - loss: 21.7688 - mean_absolute_error: 21.7688 - val_loss: 20.4090 - val_mean_absolute_error: 20.4090\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 10.29650\n",
      "Epoch 170/500\n",
      "126/126 [==============================] - 0s 230us/step - loss: 21.6778 - mean_absolute_error: 21.6778 - val_loss: 26.5864 - val_mean_absolute_error: 26.5864\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 10.29650\n",
      "Epoch 171/500\n",
      "126/126 [==============================] - 0s 255us/step - loss: 23.3941 - mean_absolute_error: 23.3941 - val_loss: 11.1508 - val_mean_absolute_error: 11.1508\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 10.29650\n",
      "Epoch 172/500\n",
      "126/126 [==============================] - 0s 252us/step - loss: 25.7338 - mean_absolute_error: 25.7338 - val_loss: 27.0071 - val_mean_absolute_error: 27.0071\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 10.29650\n",
      "Epoch 173/500\n",
      "126/126 [==============================] - 0s 239us/step - loss: 24.7684 - mean_absolute_error: 24.7684 - val_loss: 23.6045 - val_mean_absolute_error: 23.6045\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 10.29650\n",
      "Epoch 174/500\n",
      "126/126 [==============================] - 0s 205us/step - loss: 23.4781 - mean_absolute_error: 23.4781 - val_loss: 11.7149 - val_mean_absolute_error: 11.7149\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 10.29650\n",
      "Epoch 175/500\n",
      "126/126 [==============================] - 0s 185us/step - loss: 25.4438 - mean_absolute_error: 25.4438 - val_loss: 31.2441 - val_mean_absolute_error: 31.2441\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 10.29650\n",
      "Epoch 176/500\n",
      "126/126 [==============================] - 0s 156us/step - loss: 22.4993 - mean_absolute_error: 22.4993 - val_loss: 14.7755 - val_mean_absolute_error: 14.7755\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 10.29650\n",
      "Epoch 177/500\n",
      "126/126 [==============================] - 0s 165us/step - loss: 23.3688 - mean_absolute_error: 23.3688 - val_loss: 20.0212 - val_mean_absolute_error: 20.0212\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 10.29650\n",
      "Epoch 178/500\n",
      "126/126 [==============================] - 0s 175us/step - loss: 24.6721 - mean_absolute_error: 24.6721 - val_loss: 34.9792 - val_mean_absolute_error: 34.9792\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 10.29650\n",
      "Epoch 179/500\n",
      "126/126 [==============================] - 0s 151us/step - loss: 24.6532 - mean_absolute_error: 24.6532 - val_loss: 11.1257 - val_mean_absolute_error: 11.1257\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 10.29650\n",
      "Epoch 180/500\n",
      "126/126 [==============================] - 0s 198us/step - loss: 26.2961 - mean_absolute_error: 26.2961 - val_loss: 36.3246 - val_mean_absolute_error: 36.3246\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 10.29650\n",
      "Epoch 181/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 0s 161us/step - loss: 24.2201 - mean_absolute_error: 24.2201 - val_loss: 19.5536 - val_mean_absolute_error: 19.5536\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 10.29650\n",
      "Epoch 182/500\n",
      "126/126 [==============================] - 0s 157us/step - loss: 22.0215 - mean_absolute_error: 22.0215 - val_loss: 27.1667 - val_mean_absolute_error: 27.1667\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 10.29650\n",
      "Epoch 183/500\n",
      "126/126 [==============================] - 0s 225us/step - loss: 23.1182 - mean_absolute_error: 23.1182 - val_loss: 24.9430 - val_mean_absolute_error: 24.9430\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 10.29650\n",
      "Epoch 184/500\n",
      "126/126 [==============================] - 0s 153us/step - loss: 21.8170 - mean_absolute_error: 21.8170 - val_loss: 26.0808 - val_mean_absolute_error: 26.0808\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 10.29650\n",
      "Epoch 185/500\n",
      "126/126 [==============================] - 0s 161us/step - loss: 21.6366 - mean_absolute_error: 21.6366 - val_loss: 19.6067 - val_mean_absolute_error: 19.6067\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 10.29650\n",
      "Epoch 186/500\n",
      "126/126 [==============================] - 0s 158us/step - loss: 21.9230 - mean_absolute_error: 21.9230 - val_loss: 15.0164 - val_mean_absolute_error: 15.0164\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 10.29650\n",
      "Epoch 187/500\n",
      "126/126 [==============================] - 0s 248us/step - loss: 22.9611 - mean_absolute_error: 22.9611 - val_loss: 32.3546 - val_mean_absolute_error: 32.3546\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 10.29650\n",
      "Epoch 188/500\n",
      "126/126 [==============================] - 0s 251us/step - loss: 21.4423 - mean_absolute_error: 21.4423 - val_loss: 12.4543 - val_mean_absolute_error: 12.4543\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 10.29650\n",
      "Epoch 189/500\n",
      "126/126 [==============================] - 0s 292us/step - loss: 24.3629 - mean_absolute_error: 24.3629 - val_loss: 35.2187 - val_mean_absolute_error: 35.2187\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 10.29650\n",
      "Epoch 190/500\n",
      "126/126 [==============================] - 0s 260us/step - loss: 24.0376 - mean_absolute_error: 24.0376 - val_loss: 17.2233 - val_mean_absolute_error: 17.2233\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 10.29650\n",
      "Epoch 191/500\n",
      "126/126 [==============================] - 0s 270us/step - loss: 23.2010 - mean_absolute_error: 23.2010 - val_loss: 17.8171 - val_mean_absolute_error: 17.8171\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 10.29650\n",
      "Epoch 192/500\n",
      "126/126 [==============================] - 0s 290us/step - loss: 22.9563 - mean_absolute_error: 22.9563 - val_loss: 30.5292 - val_mean_absolute_error: 30.5292\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 10.29650\n",
      "Epoch 193/500\n",
      "126/126 [==============================] - 0s 224us/step - loss: 22.7626 - mean_absolute_error: 22.7626 - val_loss: 14.4770 - val_mean_absolute_error: 14.4770\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 10.29650\n",
      "Epoch 194/500\n",
      "126/126 [==============================] - 0s 232us/step - loss: 22.4825 - mean_absolute_error: 22.4825 - val_loss: 28.5181 - val_mean_absolute_error: 28.5181\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 10.29650\n",
      "Epoch 195/500\n",
      "126/126 [==============================] - 0s 199us/step - loss: 22.1116 - mean_absolute_error: 22.1116 - val_loss: 18.7578 - val_mean_absolute_error: 18.7578\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 10.29650\n",
      "Epoch 196/500\n",
      "126/126 [==============================] - 0s 124us/step - loss: 22.6102 - mean_absolute_error: 22.6102 - val_loss: 18.1053 - val_mean_absolute_error: 18.1053\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 10.29650\n",
      "Epoch 197/500\n",
      "126/126 [==============================] - 0s 210us/step - loss: 21.5879 - mean_absolute_error: 21.5879 - val_loss: 27.3866 - val_mean_absolute_error: 27.3866\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 10.29650\n",
      "Epoch 198/500\n",
      "126/126 [==============================] - 0s 198us/step - loss: 21.7059 - mean_absolute_error: 21.7059 - val_loss: 16.4473 - val_mean_absolute_error: 16.4473\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 10.29650\n",
      "Epoch 199/500\n",
      "126/126 [==============================] - 0s 167us/step - loss: 22.2519 - mean_absolute_error: 22.2519 - val_loss: 20.3314 - val_mean_absolute_error: 20.3314\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 10.29650\n",
      "Epoch 200/500\n",
      "126/126 [==============================] - 0s 194us/step - loss: 21.8945 - mean_absolute_error: 21.8945 - val_loss: 34.4114 - val_mean_absolute_error: 34.4114\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 10.29650\n",
      "Epoch 201/500\n",
      "126/126 [==============================] - ETA: 0s - loss: 18.3400 - mean_absolute_error: 18.340 - 0s 190us/step - loss: 23.2844 - mean_absolute_error: 23.2844 - val_loss: 17.7131 - val_mean_absolute_error: 17.7131\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 10.29650\n",
      "Epoch 202/500\n",
      "126/126 [==============================] - 0s 163us/step - loss: 23.3640 - mean_absolute_error: 23.3640 - val_loss: 15.2368 - val_mean_absolute_error: 15.2368\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 10.29650\n",
      "Epoch 203/500\n",
      "126/126 [==============================] - 0s 208us/step - loss: 22.3647 - mean_absolute_error: 22.3647 - val_loss: 26.4555 - val_mean_absolute_error: 26.4555\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 10.29650\n",
      "Epoch 204/500\n",
      "126/126 [==============================] - 0s 168us/step - loss: 21.5550 - mean_absolute_error: 21.5550 - val_loss: 24.6689 - val_mean_absolute_error: 24.6689\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 10.29650\n",
      "Epoch 205/500\n",
      "126/126 [==============================] - 0s 172us/step - loss: 21.5417 - mean_absolute_error: 21.5417 - val_loss: 20.1893 - val_mean_absolute_error: 20.1893\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 10.29650\n",
      "Epoch 206/500\n",
      "126/126 [==============================] - 0s 131us/step - loss: 21.2963 - mean_absolute_error: 21.2963 - val_loss: 30.5183 - val_mean_absolute_error: 30.5183\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 10.29650\n",
      "Epoch 207/500\n",
      "126/126 [==============================] - 0s 133us/step - loss: 22.3590 - mean_absolute_error: 22.3590 - val_loss: 10.5526 - val_mean_absolute_error: 10.5526\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 10.29650\n",
      "Epoch 208/500\n",
      "126/126 [==============================] - 0s 129us/step - loss: 24.4170 - mean_absolute_error: 24.4170 - val_loss: 44.7216 - val_mean_absolute_error: 44.7216\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 10.29650\n",
      "Epoch 209/500\n",
      "126/126 [==============================] - 0s 161us/step - loss: 25.2962 - mean_absolute_error: 25.2962 - val_loss: 10.5917 - val_mean_absolute_error: 10.5917\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 10.29650\n",
      "Epoch 210/500\n",
      "126/126 [==============================] - 0s 165us/step - loss: 25.3031 - mean_absolute_error: 25.3031 - val_loss: 35.1526 - val_mean_absolute_error: 35.1526\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 10.29650\n",
      "Epoch 211/500\n",
      "126/126 [==============================] - 0s 157us/step - loss: 23.3372 - mean_absolute_error: 23.3372 - val_loss: 17.3403 - val_mean_absolute_error: 17.3403\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 10.29650\n",
      "Epoch 212/500\n",
      "126/126 [==============================] - 0s 252us/step - loss: 23.4247 - mean_absolute_error: 23.4247 - val_loss: 19.8422 - val_mean_absolute_error: 19.8422\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 10.29650\n",
      "Epoch 213/500\n",
      "126/126 [==============================] - 0s 231us/step - loss: 22.5546 - mean_absolute_error: 22.5546 - val_loss: 28.4076 - val_mean_absolute_error: 28.4076\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 10.29650\n",
      "Epoch 214/500\n",
      "126/126 [==============================] - 0s 172us/step - loss: 22.2016 - mean_absolute_error: 22.2016 - val_loss: 12.1338 - val_mean_absolute_error: 12.1338\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 10.29650\n",
      "Epoch 215/500\n",
      "126/126 [==============================] - 0s 161us/step - loss: 22.6824 - mean_absolute_error: 22.6824 - val_loss: 31.6723 - val_mean_absolute_error: 31.6723\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 10.29650\n",
      "Epoch 216/500\n",
      "126/126 [==============================] - 0s 137us/step - loss: 22.7352 - mean_absolute_error: 22.7352 - val_loss: 16.8807 - val_mean_absolute_error: 16.8807\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 10.29650\n",
      "Epoch 217/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 0s 194us/step - loss: 22.2025 - mean_absolute_error: 22.2025 - val_loss: 26.2454 - val_mean_absolute_error: 26.2454\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 10.29650\n",
      "Epoch 218/500\n",
      "126/126 [==============================] - 0s 151us/step - loss: 21.7265 - mean_absolute_error: 21.7265 - val_loss: 20.9926 - val_mean_absolute_error: 20.9926\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 10.29650\n",
      "Epoch 219/500\n",
      "126/126 [==============================] - 0s 166us/step - loss: 21.7364 - mean_absolute_error: 21.7364 - val_loss: 23.1704 - val_mean_absolute_error: 23.1704\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 10.29650\n",
      "Epoch 220/500\n",
      "126/126 [==============================] - 0s 150us/step - loss: 21.9204 - mean_absolute_error: 21.9204 - val_loss: 27.0555 - val_mean_absolute_error: 27.0555\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 10.29650\n",
      "Epoch 221/500\n",
      "126/126 [==============================] - 0s 148us/step - loss: 21.6003 - mean_absolute_error: 21.6003 - val_loss: 17.8190 - val_mean_absolute_error: 17.8190\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 10.29650\n",
      "Epoch 222/500\n",
      "126/126 [==============================] - 0s 169us/step - loss: 22.2581 - mean_absolute_error: 22.2581 - val_loss: 21.9471 - val_mean_absolute_error: 21.9471\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 10.29650\n",
      "Epoch 223/500\n",
      "126/126 [==============================] - 0s 269us/step - loss: 22.4294 - mean_absolute_error: 22.4294 - val_loss: 25.8276 - val_mean_absolute_error: 25.8276\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 10.29650\n",
      "Epoch 224/500\n",
      "126/126 [==============================] - 0s 162us/step - loss: 21.4374 - mean_absolute_error: 21.4374 - val_loss: 17.2425 - val_mean_absolute_error: 17.2425\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 10.29650\n",
      "Epoch 225/500\n",
      "126/126 [==============================] - 0s 167us/step - loss: 22.4644 - mean_absolute_error: 22.4644 - val_loss: 31.7733 - val_mean_absolute_error: 31.7733\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 10.29650\n",
      "Epoch 226/500\n",
      "126/126 [==============================] - 0s 371us/step - loss: 22.5939 - mean_absolute_error: 22.5939 - val_loss: 17.1438 - val_mean_absolute_error: 17.1438\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 10.29650\n",
      "Epoch 227/500\n",
      "126/126 [==============================] - 0s 304us/step - loss: 21.6472 - mean_absolute_error: 21.6472 - val_loss: 25.4803 - val_mean_absolute_error: 25.4803\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 10.29650\n",
      "Epoch 228/500\n",
      "126/126 [==============================] - 0s 297us/step - loss: 23.2467 - mean_absolute_error: 23.2467 - val_loss: 24.1906 - val_mean_absolute_error: 24.1906\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 10.29650\n",
      "Epoch 229/500\n",
      "126/126 [==============================] - 0s 286us/step - loss: 21.5802 - mean_absolute_error: 21.5802 - val_loss: 16.4031 - val_mean_absolute_error: 16.4031\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 10.29650\n",
      "Epoch 230/500\n",
      "126/126 [==============================] - 0s 234us/step - loss: 22.7464 - mean_absolute_error: 22.7464 - val_loss: 26.6583 - val_mean_absolute_error: 26.6583\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 10.29650\n",
      "Epoch 231/500\n",
      "126/126 [==============================] - 0s 287us/step - loss: 22.1553 - mean_absolute_error: 22.1553 - val_loss: 27.0262 - val_mean_absolute_error: 27.0262\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 10.29650\n",
      "Epoch 232/500\n",
      "126/126 [==============================] - 0s 245us/step - loss: 22.5871 - mean_absolute_error: 22.5871 - val_loss: 26.0814 - val_mean_absolute_error: 26.0814\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 10.29650\n",
      "Epoch 233/500\n",
      "126/126 [==============================] - 0s 195us/step - loss: 22.4279 - mean_absolute_error: 22.4279 - val_loss: 16.2631 - val_mean_absolute_error: 16.2631\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 10.29650\n",
      "Epoch 234/500\n",
      "126/126 [==============================] - 0s 247us/step - loss: 22.2945 - mean_absolute_error: 22.2945 - val_loss: 19.7830 - val_mean_absolute_error: 19.7830\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 10.29650\n",
      "Epoch 235/500\n",
      "126/126 [==============================] - 0s 455us/step - loss: 22.7188 - mean_absolute_error: 22.7188 - val_loss: 31.7375 - val_mean_absolute_error: 31.7375\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 10.29650\n",
      "Epoch 236/500\n",
      "126/126 [==============================] - 0s 306us/step - loss: 24.8850 - mean_absolute_error: 24.8850 - val_loss: 11.5259 - val_mean_absolute_error: 11.5259\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 10.29650\n",
      "Epoch 237/500\n",
      "126/126 [==============================] - 0s 361us/step - loss: 24.0165 - mean_absolute_error: 24.0165 - val_loss: 32.4598 - val_mean_absolute_error: 32.4598\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 10.29650\n",
      "Epoch 238/500\n",
      "126/126 [==============================] - 0s 293us/step - loss: 22.1892 - mean_absolute_error: 22.1892 - val_loss: 18.0960 - val_mean_absolute_error: 18.0960\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 10.29650\n",
      "Epoch 239/500\n",
      "126/126 [==============================] - 0s 358us/step - loss: 22.3407 - mean_absolute_error: 22.3407 - val_loss: 19.1998 - val_mean_absolute_error: 19.1998\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 10.29650\n",
      "Epoch 240/500\n",
      "126/126 [==============================] - 0s 362us/step - loss: 22.2434 - mean_absolute_error: 22.2434 - val_loss: 30.2014 - val_mean_absolute_error: 30.2014\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 10.29650\n",
      "Epoch 241/500\n",
      "126/126 [==============================] - 0s 179us/step - loss: 23.7236 - mean_absolute_error: 23.7236 - val_loss: 14.7304 - val_mean_absolute_error: 14.7304\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 10.29650\n",
      "Epoch 242/500\n",
      "126/126 [==============================] - 0s 242us/step - loss: 23.6470 - mean_absolute_error: 23.6470 - val_loss: 22.5599 - val_mean_absolute_error: 22.5599\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 10.29650\n",
      "Epoch 243/500\n",
      "126/126 [==============================] - 0s 233us/step - loss: 22.1491 - mean_absolute_error: 22.1491 - val_loss: 27.0087 - val_mean_absolute_error: 27.0087\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 10.29650\n",
      "Epoch 244/500\n",
      "126/126 [==============================] - 0s 421us/step - loss: 24.0931 - mean_absolute_error: 24.0931 - val_loss: 11.0729 - val_mean_absolute_error: 11.0729\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 10.29650\n",
      "Epoch 245/500\n",
      "126/126 [==============================] - 0s 179us/step - loss: 24.6542 - mean_absolute_error: 24.6542 - val_loss: 32.6482 - val_mean_absolute_error: 32.6482\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 10.29650\n",
      "Epoch 246/500\n",
      "126/126 [==============================] - 0s 176us/step - loss: 21.4863 - mean_absolute_error: 21.4863 - val_loss: 14.6493 - val_mean_absolute_error: 14.6493\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 10.29650\n",
      "Epoch 247/500\n",
      "126/126 [==============================] - 0s 151us/step - loss: 23.6678 - mean_absolute_error: 23.6678 - val_loss: 26.2481 - val_mean_absolute_error: 26.2481\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 10.29650\n",
      "Epoch 248/500\n",
      "126/126 [==============================] - 0s 217us/step - loss: 21.9500 - mean_absolute_error: 21.9500 - val_loss: 17.4537 - val_mean_absolute_error: 17.4537\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 10.29650\n",
      "Epoch 249/500\n",
      "126/126 [==============================] - 0s 162us/step - loss: 21.4354 - mean_absolute_error: 21.4354 - val_loss: 25.0628 - val_mean_absolute_error: 25.0628\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 10.29650\n",
      "Epoch 250/500\n",
      "126/126 [==============================] - 0s 217us/step - loss: 21.6466 - mean_absolute_error: 21.6466 - val_loss: 23.6001 - val_mean_absolute_error: 23.6001\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 10.29650\n",
      "Epoch 251/500\n",
      "126/126 [==============================] - 0s 185us/step - loss: 21.8878 - mean_absolute_error: 21.8878 - val_loss: 20.9230 - val_mean_absolute_error: 20.9230\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 10.29650\n",
      "Epoch 252/500\n",
      "126/126 [==============================] - 0s 248us/step - loss: 21.7257 - mean_absolute_error: 21.7257 - val_loss: 16.7900 - val_mean_absolute_error: 16.7900\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 10.29650\n",
      "Epoch 253/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 0s 164us/step - loss: 22.2441 - mean_absolute_error: 22.2441 - val_loss: 34.9909 - val_mean_absolute_error: 34.9909\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 10.29650\n",
      "Epoch 254/500\n",
      "126/126 [==============================] - 0s 160us/step - loss: 23.7575 - mean_absolute_error: 23.7575 - val_loss: 14.1284 - val_mean_absolute_error: 14.1284\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 10.29650\n",
      "Epoch 255/500\n",
      "126/126 [==============================] - 0s 213us/step - loss: 24.3090 - mean_absolute_error: 24.3090 - val_loss: 21.3658 - val_mean_absolute_error: 21.3658\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 10.29650\n",
      "Epoch 256/500\n",
      "126/126 [==============================] - 0s 137us/step - loss: 21.7511 - mean_absolute_error: 21.7511 - val_loss: 26.1106 - val_mean_absolute_error: 26.1106\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 10.29650\n",
      "Epoch 257/500\n",
      "126/126 [==============================] - 0s 212us/step - loss: 21.5629 - mean_absolute_error: 21.5629 - val_loss: 15.1034 - val_mean_absolute_error: 15.1034\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 10.29650\n",
      "Epoch 258/500\n",
      "126/126 [==============================] - 0s 171us/step - loss: 22.8894 - mean_absolute_error: 22.8894 - val_loss: 24.9005 - val_mean_absolute_error: 24.9005\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 10.29650\n",
      "Epoch 259/500\n",
      "126/126 [==============================] - 0s 203us/step - loss: 21.3219 - mean_absolute_error: 21.3219 - val_loss: 17.3009 - val_mean_absolute_error: 17.3009\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 10.29650\n",
      "Epoch 260/500\n",
      "126/126 [==============================] - 0s 151us/step - loss: 21.4560 - mean_absolute_error: 21.4560 - val_loss: 22.6750 - val_mean_absolute_error: 22.6750\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 10.29650\n",
      "Epoch 261/500\n",
      "126/126 [==============================] - 0s 227us/step - loss: 21.1460 - mean_absolute_error: 21.1460 - val_loss: 30.4917 - val_mean_absolute_error: 30.4917\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 10.29650\n",
      "Epoch 262/500\n",
      "126/126 [==============================] - 0s 135us/step - loss: 23.0126 - mean_absolute_error: 23.0126 - val_loss: 13.3775 - val_mean_absolute_error: 13.3775\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 10.29650\n",
      "Epoch 263/500\n",
      "126/126 [==============================] - 0s 238us/step - loss: 22.0738 - mean_absolute_error: 22.0738 - val_loss: 28.2692 - val_mean_absolute_error: 28.2692\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 10.29650\n",
      "Epoch 264/500\n",
      "126/126 [==============================] - 0s 144us/step - loss: 21.5813 - mean_absolute_error: 21.5813 - val_loss: 16.3417 - val_mean_absolute_error: 16.3417\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 10.29650\n",
      "Epoch 265/500\n",
      "126/126 [==============================] - 0s 153us/step - loss: 21.7683 - mean_absolute_error: 21.7683 - val_loss: 28.1104 - val_mean_absolute_error: 28.1104\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 10.29650\n",
      "Epoch 266/500\n",
      "126/126 [==============================] - 0s 218us/step - loss: 21.7622 - mean_absolute_error: 21.7622 - val_loss: 14.4594 - val_mean_absolute_error: 14.4594\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 10.29650\n",
      "Epoch 267/500\n",
      "126/126 [==============================] - 0s 132us/step - loss: 22.1974 - mean_absolute_error: 22.1974 - val_loss: 28.9666 - val_mean_absolute_error: 28.9666\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 10.29650\n",
      "Epoch 268/500\n",
      "126/126 [==============================] - 0s 235us/step - loss: 23.0618 - mean_absolute_error: 23.0618 - val_loss: 19.5611 - val_mean_absolute_error: 19.5611\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 10.29650\n",
      "Epoch 269/500\n",
      "126/126 [==============================] - 0s 237us/step - loss: 22.7256 - mean_absolute_error: 22.7256 - val_loss: 20.7284 - val_mean_absolute_error: 20.7284\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 10.29650\n",
      "Epoch 270/500\n",
      "126/126 [==============================] - 0s 133us/step - loss: 23.3872 - mean_absolute_error: 23.3872 - val_loss: 33.3820 - val_mean_absolute_error: 33.3820\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 10.29650\n",
      "Epoch 271/500\n",
      "126/126 [==============================] - 0s 203us/step - loss: 23.7414 - mean_absolute_error: 23.7414 - val_loss: 11.4118 - val_mean_absolute_error: 11.4118\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 10.29650\n",
      "Epoch 272/500\n",
      "126/126 [==============================] - 0s 124us/step - loss: 24.6309 - mean_absolute_error: 24.6309 - val_loss: 22.0956 - val_mean_absolute_error: 22.0956\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 10.29650\n",
      "Epoch 273/500\n",
      "126/126 [==============================] - 0s 199us/step - loss: 22.4117 - mean_absolute_error: 22.4117 - val_loss: 31.4086 - val_mean_absolute_error: 31.4086\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 10.29650\n",
      "Epoch 274/500\n",
      "126/126 [==============================] - 0s 198us/step - loss: 25.8989 - mean_absolute_error: 25.8989 - val_loss: 11.3721 - val_mean_absolute_error: 11.3721\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 10.29650\n",
      "Epoch 275/500\n",
      "126/126 [==============================] - 0s 151us/step - loss: 25.5936 - mean_absolute_error: 25.5936 - val_loss: 36.0542 - val_mean_absolute_error: 36.0542\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 10.29650\n",
      "Epoch 276/500\n",
      "126/126 [==============================] - 0s 214us/step - loss: 24.8723 - mean_absolute_error: 24.8723 - val_loss: 16.5875 - val_mean_absolute_error: 16.5875\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 10.29650\n",
      "Epoch 277/500\n",
      "126/126 [==============================] - 0s 150us/step - loss: 24.2388 - mean_absolute_error: 24.2388 - val_loss: 17.5888 - val_mean_absolute_error: 17.5888\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 10.29650\n",
      "Epoch 278/500\n",
      "126/126 [==============================] - 0s 135us/step - loss: 23.5127 - mean_absolute_error: 23.5127 - val_loss: 29.0421 - val_mean_absolute_error: 29.0421\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 10.29650\n",
      "Epoch 279/500\n",
      "126/126 [==============================] - 0s 209us/step - loss: 23.4119 - mean_absolute_error: 23.4119 - val_loss: 12.3592 - val_mean_absolute_error: 12.3592\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 10.29650\n",
      "Epoch 280/500\n",
      "126/126 [==============================] - 0s 144us/step - loss: 23.3823 - mean_absolute_error: 23.3823 - val_loss: 25.1480 - val_mean_absolute_error: 25.1480\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 10.29650\n",
      "Epoch 281/500\n",
      "126/126 [==============================] - 0s 148us/step - loss: 22.0847 - mean_absolute_error: 22.0847 - val_loss: 20.6388 - val_mean_absolute_error: 20.6388\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 10.29650\n",
      "Epoch 282/500\n",
      "126/126 [==============================] - 0s 146us/step - loss: 21.4789 - mean_absolute_error: 21.4789 - val_loss: 22.9822 - val_mean_absolute_error: 22.9822\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 10.29650\n",
      "Epoch 283/500\n",
      "126/126 [==============================] - 0s 208us/step - loss: 21.8443 - mean_absolute_error: 21.8443 - val_loss: 26.5259 - val_mean_absolute_error: 26.5259\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 10.29650\n",
      "Epoch 284/500\n",
      "126/126 [==============================] - 0s 138us/step - loss: 22.1448 - mean_absolute_error: 22.1448 - val_loss: 15.9786 - val_mean_absolute_error: 15.9786\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 10.29650\n",
      "Epoch 285/500\n",
      "126/126 [==============================] - 0s 208us/step - loss: 21.5345 - mean_absolute_error: 21.5345 - val_loss: 26.4203 - val_mean_absolute_error: 26.4203\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 10.29650\n",
      "Epoch 286/500\n",
      "126/126 [==============================] - 0s 133us/step - loss: 21.4875 - mean_absolute_error: 21.4875 - val_loss: 23.5018 - val_mean_absolute_error: 23.5018\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 10.29650\n",
      "Epoch 287/500\n",
      "126/126 [==============================] - 0s 138us/step - loss: 21.5280 - mean_absolute_error: 21.5280 - val_loss: 14.4194 - val_mean_absolute_error: 14.4194\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 10.29650\n",
      "Epoch 288/500\n",
      "126/126 [==============================] - 0s 262us/step - loss: 21.9536 - mean_absolute_error: 21.9536 - val_loss: 26.6155 - val_mean_absolute_error: 26.6155\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 10.29650\n",
      "Epoch 289/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 0s 207us/step - loss: 21.0785 - mean_absolute_error: 21.0785 - val_loss: 19.0805 - val_mean_absolute_error: 19.0805\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 10.29650\n",
      "Epoch 290/500\n",
      "126/126 [==============================] - 0s 281us/step - loss: 21.0161 - mean_absolute_error: 21.0161 - val_loss: 22.7329 - val_mean_absolute_error: 22.7329\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 10.29650\n",
      "Epoch 291/500\n",
      "126/126 [==============================] - 0s 219us/step - loss: 22.4737 - mean_absolute_error: 22.4737 - val_loss: 29.9769 - val_mean_absolute_error: 29.9769\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 10.29650\n",
      "Epoch 292/500\n",
      "126/126 [==============================] - 0s 234us/step - loss: 22.5973 - mean_absolute_error: 22.5973 - val_loss: 26.0851 - val_mean_absolute_error: 26.0851\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 10.29650\n",
      "Epoch 293/500\n",
      "126/126 [==============================] - 0s 239us/step - loss: 23.1511 - mean_absolute_error: 23.1511 - val_loss: 14.3123 - val_mean_absolute_error: 14.3123\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 10.29650\n",
      "Epoch 294/500\n",
      "126/126 [==============================] - 0s 259us/step - loss: 23.0702 - mean_absolute_error: 23.0702 - val_loss: 25.1244 - val_mean_absolute_error: 25.1244\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 10.29650\n",
      "Epoch 295/500\n",
      "126/126 [==============================] - 0s 216us/step - loss: 21.1267 - mean_absolute_error: 21.1267 - val_loss: 20.5739 - val_mean_absolute_error: 20.5739\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 10.29650\n",
      "Epoch 296/500\n",
      "126/126 [==============================] - 0s 231us/step - loss: 22.0745 - mean_absolute_error: 22.0745 - val_loss: 14.2782 - val_mean_absolute_error: 14.2782\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 10.29650\n",
      "Epoch 297/500\n",
      "126/126 [==============================] - 0s 387us/step - loss: 21.6444 - mean_absolute_error: 21.6444 - val_loss: 28.9965 - val_mean_absolute_error: 28.9965\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 10.29650\n",
      "Epoch 298/500\n",
      "126/126 [==============================] - 0s 165us/step - loss: 23.3632 - mean_absolute_error: 23.3632 - val_loss: 17.3683 - val_mean_absolute_error: 17.3683\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 10.29650\n",
      "Epoch 299/500\n",
      "126/126 [==============================] - 0s 198us/step - loss: 22.6559 - mean_absolute_error: 22.6559 - val_loss: 22.5384 - val_mean_absolute_error: 22.5384\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 10.29650\n",
      "Epoch 300/500\n",
      "126/126 [==============================] - 0s 239us/step - loss: 21.0658 - mean_absolute_error: 21.0658 - val_loss: 19.3973 - val_mean_absolute_error: 19.3973\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 10.29650\n",
      "Epoch 301/500\n",
      "126/126 [==============================] - 0s 222us/step - loss: 22.0108 - mean_absolute_error: 22.0108 - val_loss: 15.1679 - val_mean_absolute_error: 15.1679\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 10.29650\n",
      "Epoch 302/500\n",
      "126/126 [==============================] - 0s 193us/step - loss: 22.1782 - mean_absolute_error: 22.1782 - val_loss: 24.5724 - val_mean_absolute_error: 24.5724\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 10.29650\n",
      "Epoch 303/500\n",
      "126/126 [==============================] - 0s 299us/step - loss: 21.7569 - mean_absolute_error: 21.7569 - val_loss: 16.5616 - val_mean_absolute_error: 16.5616\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 10.29650\n",
      "Epoch 304/500\n",
      "126/126 [==============================] - 0s 249us/step - loss: 21.3740 - mean_absolute_error: 21.3740 - val_loss: 22.1530 - val_mean_absolute_error: 22.1530\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 10.29650\n",
      "Epoch 305/500\n",
      "126/126 [==============================] - 0s 255us/step - loss: 22.6087 - mean_absolute_error: 22.6087 - val_loss: 27.7613 - val_mean_absolute_error: 27.7613\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 10.29650\n",
      "Epoch 306/500\n",
      "126/126 [==============================] - 0s 212us/step - loss: 22.3082 - mean_absolute_error: 22.3082 - val_loss: 11.4902 - val_mean_absolute_error: 11.4902\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 10.29650\n",
      "Epoch 307/500\n",
      "126/126 [==============================] - 0s 243us/step - loss: 23.7404 - mean_absolute_error: 23.7404 - val_loss: 28.2828 - val_mean_absolute_error: 28.2828\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 10.29650\n",
      "Epoch 308/500\n",
      "126/126 [==============================] - 0s 208us/step - loss: 23.3611 - mean_absolute_error: 23.3611 - val_loss: 19.1282 - val_mean_absolute_error: 19.1282\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 10.29650\n",
      "Epoch 309/500\n",
      "126/126 [==============================] - 0s 199us/step - loss: 21.5510 - mean_absolute_error: 21.5510 - val_loss: 21.1349 - val_mean_absolute_error: 21.1349\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 10.29650\n",
      "Epoch 310/500\n",
      "126/126 [==============================] - 0s 221us/step - loss: 22.4547 - mean_absolute_error: 22.4547 - val_loss: 30.2407 - val_mean_absolute_error: 30.2407\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 10.29650\n",
      "Epoch 311/500\n",
      "126/126 [==============================] - 0s 220us/step - loss: 23.1720 - mean_absolute_error: 23.1720 - val_loss: 13.1521 - val_mean_absolute_error: 13.1521\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 10.29650\n",
      "Epoch 312/500\n",
      "126/126 [==============================] - 0s 282us/step - loss: 23.8295 - mean_absolute_error: 23.8295 - val_loss: 31.0753 - val_mean_absolute_error: 31.0753\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 10.29650\n",
      "Epoch 313/500\n",
      "126/126 [==============================] - 0s 182us/step - loss: 22.6783 - mean_absolute_error: 22.6783 - val_loss: 18.1737 - val_mean_absolute_error: 18.1737\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 10.29650\n",
      "Epoch 314/500\n",
      "126/126 [==============================] - 0s 156us/step - loss: 22.0430 - mean_absolute_error: 22.0430 - val_loss: 23.0215 - val_mean_absolute_error: 23.0215\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 10.29650\n",
      "Epoch 315/500\n",
      "126/126 [==============================] - 0s 227us/step - loss: 21.1488 - mean_absolute_error: 21.1488 - val_loss: 20.8912 - val_mean_absolute_error: 20.8912\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 10.29650\n",
      "Epoch 316/500\n",
      "126/126 [==============================] - 0s 207us/step - loss: 21.3890 - mean_absolute_error: 21.3890 - val_loss: 23.9479 - val_mean_absolute_error: 23.9479\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 10.29650\n",
      "Epoch 317/500\n",
      "126/126 [==============================] - 0s 139us/step - loss: 21.4215 - mean_absolute_error: 21.4215 - val_loss: 18.4347 - val_mean_absolute_error: 18.4347\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 10.29650\n",
      "Epoch 318/500\n",
      "126/126 [==============================] - 0s 128us/step - loss: 20.9251 - mean_absolute_error: 20.9251 - val_loss: 20.6402 - val_mean_absolute_error: 20.6402\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 10.29650\n",
      "Epoch 319/500\n",
      "126/126 [==============================] - 0s 132us/step - loss: 21.9972 - mean_absolute_error: 21.9972 - val_loss: 23.5979 - val_mean_absolute_error: 23.5979\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 10.29650\n",
      "Epoch 320/500\n",
      "126/126 [==============================] - 0s 216us/step - loss: 20.8415 - mean_absolute_error: 20.8415 - val_loss: 23.7932 - val_mean_absolute_error: 23.7932\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 10.29650\n",
      "Epoch 321/500\n",
      "126/126 [==============================] - 0s 225us/step - loss: 21.2203 - mean_absolute_error: 21.2203 - val_loss: 16.4373 - val_mean_absolute_error: 16.4373\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 10.29650\n",
      "Epoch 322/500\n",
      "126/126 [==============================] - 0s 145us/step - loss: 20.9618 - mean_absolute_error: 20.9618 - val_loss: 24.3461 - val_mean_absolute_error: 24.3461\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 10.29650\n",
      "Epoch 323/500\n",
      "126/126 [==============================] - 0s 208us/step - loss: 22.5785 - mean_absolute_error: 22.5785 - val_loss: 22.4587 - val_mean_absolute_error: 22.4587\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 10.29650\n",
      "Epoch 324/500\n",
      "126/126 [==============================] - 0s 155us/step - loss: 21.2264 - mean_absolute_error: 21.2264 - val_loss: 17.0928 - val_mean_absolute_error: 17.0928\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 10.29650\n",
      "Epoch 325/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 0s 341us/step - loss: 21.4669 - mean_absolute_error: 21.4669 - val_loss: 26.2671 - val_mean_absolute_error: 26.2671\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 10.29650\n",
      "Epoch 326/500\n",
      "126/126 [==============================] - 0s 171us/step - loss: 21.1659 - mean_absolute_error: 21.1659 - val_loss: 21.4356 - val_mean_absolute_error: 21.4356\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 10.29650\n",
      "Epoch 327/500\n",
      "126/126 [==============================] - 0s 232us/step - loss: 21.4919 - mean_absolute_error: 21.4919 - val_loss: 14.9642 - val_mean_absolute_error: 14.9642\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 10.29650\n",
      "Epoch 328/500\n",
      "126/126 [==============================] - 0s 228us/step - loss: 23.4363 - mean_absolute_error: 23.4363 - val_loss: 35.6390 - val_mean_absolute_error: 35.6390\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 10.29650\n",
      "Epoch 329/500\n",
      "126/126 [==============================] - 0s 172us/step - loss: 25.6479 - mean_absolute_error: 25.6479 - val_loss: 14.3256 - val_mean_absolute_error: 14.3256\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 10.29650\n",
      "Epoch 330/500\n",
      "126/126 [==============================] - 0s 228us/step - loss: 22.1982 - mean_absolute_error: 22.1982 - val_loss: 20.2257 - val_mean_absolute_error: 20.2257\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 10.29650\n",
      "Epoch 331/500\n",
      "126/126 [==============================] - 0s 177us/step - loss: 21.8663 - mean_absolute_error: 21.8663 - val_loss: 33.1303 - val_mean_absolute_error: 33.1303\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 10.29650\n",
      "Epoch 332/500\n",
      "126/126 [==============================] - 0s 227us/step - loss: 24.8503 - mean_absolute_error: 24.8503 - val_loss: 10.5136 - val_mean_absolute_error: 10.5136\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 10.29650\n",
      "Epoch 333/500\n",
      "126/126 [==============================] - 0s 206us/step - loss: 23.9787 - mean_absolute_error: 23.9787 - val_loss: 42.7438 - val_mean_absolute_error: 42.7438\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 10.29650\n",
      "Epoch 334/500\n",
      "126/126 [==============================] - 0s 210us/step - loss: 26.3511 - mean_absolute_error: 26.3511 - val_loss: 11.8807 - val_mean_absolute_error: 11.8807\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 10.29650\n",
      "Epoch 335/500\n",
      "126/126 [==============================] - 0s 155us/step - loss: 25.5489 - mean_absolute_error: 25.5489 - val_loss: 39.1093 - val_mean_absolute_error: 39.1093\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 10.29650\n",
      "Epoch 336/500\n",
      "126/126 [==============================] - 0s 214us/step - loss: 23.7156 - mean_absolute_error: 23.7156 - val_loss: 11.3497 - val_mean_absolute_error: 11.3497\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 10.29650\n",
      "Epoch 337/500\n",
      "126/126 [==============================] - 0s 128us/step - loss: 24.4654 - mean_absolute_error: 24.4654 - val_loss: 34.3804 - val_mean_absolute_error: 34.3804\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 10.29650\n",
      "Epoch 338/500\n",
      "126/126 [==============================] - 0s 143us/step - loss: 24.9830 - mean_absolute_error: 24.9830 - val_loss: 17.9699 - val_mean_absolute_error: 17.9699\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 10.29650\n",
      "Epoch 339/500\n",
      "126/126 [==============================] - 0s 220us/step - loss: 22.1788 - mean_absolute_error: 22.1788 - val_loss: 17.4787 - val_mean_absolute_error: 17.4787\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 10.29650\n",
      "Epoch 340/500\n",
      "126/126 [==============================] - 0s 159us/step - loss: 21.4063 - mean_absolute_error: 21.4063 - val_loss: 20.0504 - val_mean_absolute_error: 20.0504\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 10.29650\n",
      "Epoch 341/500\n",
      "126/126 [==============================] - 0s 164us/step - loss: 20.7141 - mean_absolute_error: 20.7141 - val_loss: 24.9237 - val_mean_absolute_error: 24.9237\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 10.29650\n",
      "Epoch 342/500\n",
      "126/126 [==============================] - 0s 203us/step - loss: 21.3090 - mean_absolute_error: 21.3090 - val_loss: 26.2181 - val_mean_absolute_error: 26.2181\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 10.29650\n",
      "Epoch 343/500\n",
      "126/126 [==============================] - 0s 146us/step - loss: 21.5000 - mean_absolute_error: 21.5000 - val_loss: 21.8033 - val_mean_absolute_error: 21.8033\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 10.29650\n",
      "Epoch 344/500\n",
      "126/126 [==============================] - 0s 157us/step - loss: 21.4423 - mean_absolute_error: 21.4423 - val_loss: 21.3355 - val_mean_absolute_error: 21.3355\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 10.29650\n",
      "Epoch 345/500\n",
      "126/126 [==============================] - 0s 201us/step - loss: 23.0601 - mean_absolute_error: 23.0601 - val_loss: 35.7797 - val_mean_absolute_error: 35.7797\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 10.29650\n",
      "Epoch 346/500\n",
      "126/126 [==============================] - 0s 160us/step - loss: 24.3488 - mean_absolute_error: 24.3488 - val_loss: 13.2351 - val_mean_absolute_error: 13.2351\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 10.29650\n",
      "Epoch 347/500\n",
      "126/126 [==============================] - 0s 147us/step - loss: 23.0056 - mean_absolute_error: 23.0056 - val_loss: 30.8028 - val_mean_absolute_error: 30.8028\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 10.29650\n",
      "Epoch 348/500\n",
      "126/126 [==============================] - 0s 192us/step - loss: 25.5127 - mean_absolute_error: 25.5127 - val_loss: 17.9156 - val_mean_absolute_error: 17.9156\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 10.29650\n",
      "Epoch 349/500\n",
      "126/126 [==============================] - 0s 167us/step - loss: 23.1157 - mean_absolute_error: 23.1157 - val_loss: 13.4567 - val_mean_absolute_error: 13.4567\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 10.29650\n",
      "Epoch 350/500\n",
      "126/126 [==============================] - 0s 203us/step - loss: 23.0661 - mean_absolute_error: 23.0661 - val_loss: 34.6109 - val_mean_absolute_error: 34.6109\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 10.29650\n",
      "Epoch 351/500\n",
      "126/126 [==============================] - 0s 133us/step - loss: 23.5982 - mean_absolute_error: 23.5982 - val_loss: 11.5838 - val_mean_absolute_error: 11.5838\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 10.29650\n",
      "Epoch 352/500\n",
      "126/126 [==============================] - 0s 174us/step - loss: 22.4272 - mean_absolute_error: 22.4272 - val_loss: 32.3906 - val_mean_absolute_error: 32.3906\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 10.29650\n",
      "Epoch 353/500\n",
      "126/126 [==============================] - 0s 126us/step - loss: 21.5547 - mean_absolute_error: 21.5547 - val_loss: 13.5603 - val_mean_absolute_error: 13.5603\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 10.29650\n",
      "Epoch 354/500\n",
      "126/126 [==============================] - 0s 218us/step - loss: 23.6895 - mean_absolute_error: 23.6895 - val_loss: 25.8045 - val_mean_absolute_error: 25.8045\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 10.29650\n",
      "Epoch 355/500\n",
      "126/126 [==============================] - 0s 132us/step - loss: 21.7595 - mean_absolute_error: 21.7595 - val_loss: 18.6042 - val_mean_absolute_error: 18.6042\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 10.29650\n",
      "Epoch 356/500\n",
      "126/126 [==============================] - 0s 258us/step - loss: 21.6608 - mean_absolute_error: 21.6608 - val_loss: 17.9788 - val_mean_absolute_error: 17.9788\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 10.29650\n",
      "Epoch 357/500\n",
      "126/126 [==============================] - 0s 160us/step - loss: 21.1375 - mean_absolute_error: 21.1375 - val_loss: 25.6740 - val_mean_absolute_error: 25.6740\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 10.29650\n",
      "Epoch 358/500\n",
      "126/126 [==============================] - 0s 323us/step - loss: 21.5234 - mean_absolute_error: 21.5234 - val_loss: 16.7802 - val_mean_absolute_error: 16.7802\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 10.29650\n",
      "Epoch 359/500\n",
      "126/126 [==============================] - 0s 233us/step - loss: 20.5966 - mean_absolute_error: 20.5966 - val_loss: 29.7522 - val_mean_absolute_error: 29.7522\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 10.29650\n",
      "Epoch 360/500\n",
      "126/126 [==============================] - 0s 243us/step - loss: 21.8757 - mean_absolute_error: 21.8757 - val_loss: 16.3183 - val_mean_absolute_error: 16.3183\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 10.29650\n",
      "Epoch 361/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 0s 254us/step - loss: 21.3026 - mean_absolute_error: 21.3026 - val_loss: 24.3720 - val_mean_absolute_error: 24.3720\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 10.29650\n",
      "Epoch 362/500\n",
      "126/126 [==============================] - 0s 159us/step - loss: 21.1125 - mean_absolute_error: 21.1125 - val_loss: 20.3591 - val_mean_absolute_error: 20.3591\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 10.29650\n",
      "Epoch 363/500\n",
      "126/126 [==============================] - 0s 224us/step - loss: 20.8467 - mean_absolute_error: 20.8467 - val_loss: 28.2435 - val_mean_absolute_error: 28.2435\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 10.29650\n",
      "Epoch 364/500\n",
      "126/126 [==============================] - 0s 204us/step - loss: 21.2467 - mean_absolute_error: 21.2467 - val_loss: 20.4010 - val_mean_absolute_error: 20.4010\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 10.29650\n",
      "Epoch 365/500\n",
      "126/126 [==============================] - 0s 164us/step - loss: 20.9393 - mean_absolute_error: 20.9393 - val_loss: 19.5203 - val_mean_absolute_error: 19.5203\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 10.29650\n",
      "Epoch 366/500\n",
      "126/126 [==============================] - 0s 219us/step - loss: 22.3310 - mean_absolute_error: 22.3310 - val_loss: 30.2223 - val_mean_absolute_error: 30.2223\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 10.29650\n",
      "Epoch 367/500\n",
      "126/126 [==============================] - 0s 294us/step - loss: 23.7291 - mean_absolute_error: 23.7291 - val_loss: 22.3356 - val_mean_absolute_error: 22.3356\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 10.29650\n",
      "Epoch 368/500\n",
      "126/126 [==============================] - 0s 257us/step - loss: 23.3494 - mean_absolute_error: 23.3494 - val_loss: 11.7123 - val_mean_absolute_error: 11.7123\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 10.29650\n",
      "Epoch 369/500\n",
      "126/126 [==============================] - 0s 269us/step - loss: 24.5617 - mean_absolute_error: 24.5617 - val_loss: 28.4926 - val_mean_absolute_error: 28.4926\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 10.29650\n",
      "Epoch 370/500\n",
      "126/126 [==============================] - 0s 196us/step - loss: 20.9788 - mean_absolute_error: 20.9788 - val_loss: 13.3999 - val_mean_absolute_error: 13.3999\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 10.29650\n",
      "Epoch 371/500\n",
      "126/126 [==============================] - 0s 214us/step - loss: 23.9890 - mean_absolute_error: 23.9890 - val_loss: 27.0847 - val_mean_absolute_error: 27.0847\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 10.29650\n",
      "Epoch 372/500\n",
      "126/126 [==============================] - 0s 219us/step - loss: 23.1668 - mean_absolute_error: 23.1668 - val_loss: 18.6006 - val_mean_absolute_error: 18.6006\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 10.29650\n",
      "Epoch 373/500\n",
      "126/126 [==============================] - 0s 166us/step - loss: 22.3515 - mean_absolute_error: 22.3515 - val_loss: 21.1130 - val_mean_absolute_error: 21.1130\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 10.29650\n",
      "Epoch 374/500\n",
      "126/126 [==============================] - 0s 240us/step - loss: 22.5152 - mean_absolute_error: 22.5152 - val_loss: 24.1349 - val_mean_absolute_error: 24.1349\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 10.29650\n",
      "Epoch 375/500\n",
      "126/126 [==============================] - 0s 207us/step - loss: 23.2553 - mean_absolute_error: 23.2553 - val_loss: 15.4721 - val_mean_absolute_error: 15.4721\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 10.29650\n",
      "Epoch 376/500\n",
      "126/126 [==============================] - 0s 144us/step - loss: 21.3201 - mean_absolute_error: 21.3201 - val_loss: 30.3117 - val_mean_absolute_error: 30.3117\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 10.29650\n",
      "Epoch 377/500\n",
      "126/126 [==============================] - 0s 144us/step - loss: 22.1277 - mean_absolute_error: 22.1277 - val_loss: 15.2779 - val_mean_absolute_error: 15.2779\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 10.29650\n",
      "Epoch 378/500\n",
      "126/126 [==============================] - ETA: 0s - loss: 34.2247 - mean_absolute_error: 34.224 - 0s 148us/step - loss: 21.2056 - mean_absolute_error: 21.2056 - val_loss: 21.1506 - val_mean_absolute_error: 21.1506\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 10.29650\n",
      "Epoch 379/500\n",
      "126/126 [==============================] - 0s 152us/step - loss: 20.7946 - mean_absolute_error: 20.7946 - val_loss: 19.1527 - val_mean_absolute_error: 19.1527\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 10.29650\n",
      "Epoch 380/500\n",
      "126/126 [==============================] - 0s 219us/step - loss: 20.5620 - mean_absolute_error: 20.5620 - val_loss: 21.7652 - val_mean_absolute_error: 21.7652\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 10.29650\n",
      "Epoch 381/500\n",
      "126/126 [==============================] - 0s 235us/step - loss: 21.2675 - mean_absolute_error: 21.2675 - val_loss: 14.6757 - val_mean_absolute_error: 14.6757\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 10.29650\n",
      "Epoch 382/500\n",
      "126/126 [==============================] - 0s 140us/step - loss: 23.2417 - mean_absolute_error: 23.2417 - val_loss: 37.7385 - val_mean_absolute_error: 37.7385\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 10.29650\n",
      "Epoch 383/500\n",
      "126/126 [==============================] - 0s 138us/step - loss: 23.0784 - mean_absolute_error: 23.0784 - val_loss: 12.5116 - val_mean_absolute_error: 12.5116\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 10.29650\n",
      "Epoch 384/500\n",
      "126/126 [==============================] - 0s 217us/step - loss: 25.8655 - mean_absolute_error: 25.8655 - val_loss: 33.3619 - val_mean_absolute_error: 33.3619\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 10.29650\n",
      "Epoch 385/500\n",
      "126/126 [==============================] - 0s 137us/step - loss: 22.6963 - mean_absolute_error: 22.6963 - val_loss: 15.3451 - val_mean_absolute_error: 15.3451\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 10.29650\n",
      "Epoch 386/500\n",
      "126/126 [==============================] - 0s 251us/step - loss: 22.7323 - mean_absolute_error: 22.7323 - val_loss: 28.3519 - val_mean_absolute_error: 28.3519\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 10.29650\n",
      "Epoch 387/500\n",
      "126/126 [==============================] - 0s 233us/step - loss: 22.2407 - mean_absolute_error: 22.2407 - val_loss: 20.3436 - val_mean_absolute_error: 20.3436\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 10.29650\n",
      "Epoch 388/500\n",
      "126/126 [==============================] - 0s 301us/step - loss: 22.3786 - mean_absolute_error: 22.3786 - val_loss: 13.6762 - val_mean_absolute_error: 13.6762\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 10.29650\n",
      "Epoch 389/500\n",
      "126/126 [==============================] - 0s 211us/step - loss: 21.7854 - mean_absolute_error: 21.7854 - val_loss: 29.9119 - val_mean_absolute_error: 29.9119\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 10.29650\n",
      "Epoch 390/500\n",
      "126/126 [==============================] - 0s 149us/step - loss: 21.7038 - mean_absolute_error: 21.7038 - val_loss: 18.2971 - val_mean_absolute_error: 18.2971\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 10.29650\n",
      "Epoch 391/500\n",
      "126/126 [==============================] - 0s 203us/step - loss: 20.8811 - mean_absolute_error: 20.8811 - val_loss: 24.5069 - val_mean_absolute_error: 24.5069\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 10.29650\n",
      "Epoch 392/500\n",
      "126/126 [==============================] - 0s 216us/step - loss: 20.5457 - mean_absolute_error: 20.5457 - val_loss: 19.2169 - val_mean_absolute_error: 19.2169\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 10.29650\n",
      "Epoch 393/500\n",
      "126/126 [==============================] - 0s 289us/step - loss: 20.8428 - mean_absolute_error: 20.8428 - val_loss: 32.7523 - val_mean_absolute_error: 32.7523\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 10.29650\n",
      "Epoch 394/500\n",
      "126/126 [==============================] - 0s 152us/step - loss: 21.6142 - mean_absolute_error: 21.6142 - val_loss: 11.9092 - val_mean_absolute_error: 11.9092\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 10.29650\n",
      "Epoch 395/500\n",
      "126/126 [==============================] - 0s 195us/step - loss: 22.8281 - mean_absolute_error: 22.8281 - val_loss: 32.1622 - val_mean_absolute_error: 32.1622\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 10.29650\n",
      "Epoch 396/500\n",
      "126/126 [==============================] - 0s 220us/step - loss: 24.3875 - mean_absolute_error: 24.3875 - val_loss: 13.9757 - val_mean_absolute_error: 13.9757\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 10.29650\n",
      "Epoch 397/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 0s 133us/step - loss: 23.8080 - mean_absolute_error: 23.8080 - val_loss: 17.4839 - val_mean_absolute_error: 17.4839\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 10.29650\n",
      "Epoch 398/500\n",
      "126/126 [==============================] - 0s 150us/step - loss: 23.0233 - mean_absolute_error: 23.0233 - val_loss: 28.5183 - val_mean_absolute_error: 28.5183\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 10.29650\n",
      "Epoch 399/500\n",
      "126/126 [==============================] - 0s 223us/step - loss: 22.2873 - mean_absolute_error: 22.2873 - val_loss: 15.6391 - val_mean_absolute_error: 15.6391\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 10.29650\n",
      "Epoch 400/500\n",
      "126/126 [==============================] - 0s 231us/step - loss: 21.6553 - mean_absolute_error: 21.6553 - val_loss: 22.3137 - val_mean_absolute_error: 22.3137\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 10.29650\n",
      "Epoch 401/500\n",
      "126/126 [==============================] - 0s 135us/step - loss: 20.5142 - mean_absolute_error: 20.5142 - val_loss: 16.3810 - val_mean_absolute_error: 16.3810\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 10.29650\n",
      "Epoch 402/500\n",
      "126/126 [==============================] - 0s 162us/step - loss: 21.5258 - mean_absolute_error: 21.5258 - val_loss: 26.1640 - val_mean_absolute_error: 26.1640\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 10.29650\n",
      "Epoch 403/500\n",
      "126/126 [==============================] - 0s 242us/step - loss: 22.5423 - mean_absolute_error: 22.5423 - val_loss: 26.0603 - val_mean_absolute_error: 26.0603\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 10.29650\n",
      "Epoch 404/500\n",
      "126/126 [==============================] - 0s 224us/step - loss: 21.3066 - mean_absolute_error: 21.3066 - val_loss: 15.4413 - val_mean_absolute_error: 15.4413\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 10.29650\n",
      "Epoch 405/500\n",
      "126/126 [==============================] - 0s 150us/step - loss: 22.3027 - mean_absolute_error: 22.3027 - val_loss: 26.5234 - val_mean_absolute_error: 26.5234\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 10.29650\n",
      "Epoch 406/500\n",
      "126/126 [==============================] - 0s 168us/step - loss: 21.1221 - mean_absolute_error: 21.1221 - val_loss: 18.7869 - val_mean_absolute_error: 18.7869\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 10.29650\n",
      "Epoch 407/500\n",
      "126/126 [==============================] - 0s 253us/step - loss: 22.5757 - mean_absolute_error: 22.5757 - val_loss: 13.6400 - val_mean_absolute_error: 13.6400\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 10.29650\n",
      "Epoch 408/500\n",
      "126/126 [==============================] - 0s 161us/step - loss: 22.6439 - mean_absolute_error: 22.6439 - val_loss: 34.2495 - val_mean_absolute_error: 34.2495\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 10.29650\n",
      "Epoch 409/500\n",
      "126/126 [==============================] - 0s 196us/step - loss: 20.8386 - mean_absolute_error: 20.8386 - val_loss: 12.5314 - val_mean_absolute_error: 12.5314\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 10.29650\n",
      "Epoch 410/500\n",
      "126/126 [==============================] - 0s 152us/step - loss: 23.3833 - mean_absolute_error: 23.3833 - val_loss: 27.1180 - val_mean_absolute_error: 27.1180\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 10.29650\n",
      "Epoch 411/500\n",
      "126/126 [==============================] - 0s 188us/step - loss: 20.5669 - mean_absolute_error: 20.5669 - val_loss: 20.0213 - val_mean_absolute_error: 20.0213\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 10.29650\n",
      "Epoch 412/500\n",
      "126/126 [==============================] - 0s 171us/step - loss: 20.7924 - mean_absolute_error: 20.7924 - val_loss: 20.6693 - val_mean_absolute_error: 20.6693\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 10.29650\n",
      "Epoch 413/500\n",
      "126/126 [==============================] - 0s 158us/step - loss: 20.6112 - mean_absolute_error: 20.6112 - val_loss: 22.5915 - val_mean_absolute_error: 22.5915\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 10.29650\n",
      "Epoch 414/500\n",
      "126/126 [==============================] - 0s 223us/step - loss: 21.9520 - mean_absolute_error: 21.9520 - val_loss: 18.2178 - val_mean_absolute_error: 18.2178\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 10.29650\n",
      "Epoch 415/500\n",
      "126/126 [==============================] - 0s 261us/step - loss: 21.2027 - mean_absolute_error: 21.2027 - val_loss: 24.8513 - val_mean_absolute_error: 24.8513\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 10.29650\n",
      "Epoch 416/500\n",
      "126/126 [==============================] - 0s 217us/step - loss: 20.5638 - mean_absolute_error: 20.5638 - val_loss: 28.5375 - val_mean_absolute_error: 28.5375\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 10.29650\n",
      "Epoch 417/500\n",
      "126/126 [==============================] - 0s 142us/step - loss: 21.0890 - mean_absolute_error: 21.0890 - val_loss: 14.0080 - val_mean_absolute_error: 14.0080\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 10.29650\n",
      "Epoch 418/500\n",
      "126/126 [==============================] - 0s 151us/step - loss: 21.4450 - mean_absolute_error: 21.4450 - val_loss: 30.4405 - val_mean_absolute_error: 30.4405\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 10.29650\n",
      "Epoch 419/500\n",
      "126/126 [==============================] - 0s 147us/step - loss: 20.9711 - mean_absolute_error: 20.9711 - val_loss: 15.6521 - val_mean_absolute_error: 15.6521\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 10.29650\n",
      "Epoch 420/500\n",
      "126/126 [==============================] - 0s 192us/step - loss: 21.7391 - mean_absolute_error: 21.7391 - val_loss: 22.3739 - val_mean_absolute_error: 22.3739\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 10.29650\n",
      "Epoch 421/500\n",
      "126/126 [==============================] - 0s 292us/step - loss: 21.1535 - mean_absolute_error: 21.1535 - val_loss: 29.5316 - val_mean_absolute_error: 29.5316\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 10.29650\n",
      "Epoch 422/500\n",
      "126/126 [==============================] - 0s 176us/step - loss: 21.0657 - mean_absolute_error: 21.0657 - val_loss: 18.2810 - val_mean_absolute_error: 18.2810\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 10.29650\n",
      "Epoch 423/500\n",
      "126/126 [==============================] - 0s 311us/step - loss: 21.0223 - mean_absolute_error: 21.0223 - val_loss: 19.9077 - val_mean_absolute_error: 19.9077\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 10.29650\n",
      "Epoch 424/500\n",
      "126/126 [==============================] - 0s 252us/step - loss: 21.4591 - mean_absolute_error: 21.4591 - val_loss: 23.0467 - val_mean_absolute_error: 23.0467\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 10.29650\n",
      "Epoch 425/500\n",
      "126/126 [==============================] - 0s 223us/step - loss: 20.3674 - mean_absolute_error: 20.3674 - val_loss: 20.6428 - val_mean_absolute_error: 20.6428\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 10.29650\n",
      "Epoch 426/500\n",
      "126/126 [==============================] - 0s 269us/step - loss: 21.1146 - mean_absolute_error: 21.1146 - val_loss: 17.3793 - val_mean_absolute_error: 17.3793\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 10.29650\n",
      "Epoch 427/500\n",
      "126/126 [==============================] - 0s 155us/step - loss: 20.8581 - mean_absolute_error: 20.8581 - val_loss: 32.8289 - val_mean_absolute_error: 32.8289\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 10.29650\n",
      "Epoch 428/500\n",
      "126/126 [==============================] - 0s 237us/step - loss: 23.0343 - mean_absolute_error: 23.0343 - val_loss: 16.2636 - val_mean_absolute_error: 16.2636\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 10.29650\n",
      "Epoch 429/500\n",
      "126/126 [==============================] - 0s 378us/step - loss: 22.1311 - mean_absolute_error: 22.1311 - val_loss: 19.7205 - val_mean_absolute_error: 19.7205\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 10.29650\n",
      "Epoch 430/500\n",
      "126/126 [==============================] - 0s 255us/step - loss: 21.2094 - mean_absolute_error: 21.2094 - val_loss: 22.6962 - val_mean_absolute_error: 22.6962\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 10.29650\n",
      "Epoch 431/500\n",
      "126/126 [==============================] - 0s 264us/step - loss: 21.6794 - mean_absolute_error: 21.6794 - val_loss: 15.0434 - val_mean_absolute_error: 15.0434\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 10.29650\n",
      "Epoch 432/500\n",
      "126/126 [==============================] - 0s 247us/step - loss: 21.5415 - mean_absolute_error: 21.5415 - val_loss: 17.1148 - val_mean_absolute_error: 17.1148\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 10.29650\n",
      "Epoch 433/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 0s 225us/step - loss: 20.8739 - mean_absolute_error: 20.8739 - val_loss: 28.5482 - val_mean_absolute_error: 28.5482\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 10.29650\n",
      "Epoch 434/500\n",
      "126/126 [==============================] - 0s 270us/step - loss: 21.5444 - mean_absolute_error: 21.5444 - val_loss: 18.9009 - val_mean_absolute_error: 18.9009\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 10.29650\n",
      "Epoch 435/500\n",
      "126/126 [==============================] - 0s 148us/step - loss: 20.8876 - mean_absolute_error: 20.8876 - val_loss: 21.8608 - val_mean_absolute_error: 21.8608\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 10.29650\n",
      "Epoch 436/500\n",
      "126/126 [==============================] - 0s 182us/step - loss: 20.3327 - mean_absolute_error: 20.3327 - val_loss: 21.6854 - val_mean_absolute_error: 21.6854\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 10.29650\n",
      "Epoch 437/500\n",
      "126/126 [==============================] - 0s 244us/step - loss: 20.5004 - mean_absolute_error: 20.5004 - val_loss: 20.6463 - val_mean_absolute_error: 20.6463\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 10.29650\n",
      "Epoch 438/500\n",
      "126/126 [==============================] - 0s 145us/step - loss: 19.8333 - mean_absolute_error: 19.8333 - val_loss: 20.4689 - val_mean_absolute_error: 20.4689\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 10.29650\n",
      "Epoch 439/500\n",
      "126/126 [==============================] - 0s 179us/step - loss: 19.8205 - mean_absolute_error: 19.8205 - val_loss: 22.6390 - val_mean_absolute_error: 22.6390\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 10.29650\n",
      "Epoch 440/500\n",
      "126/126 [==============================] - 0s 179us/step - loss: 20.0152 - mean_absolute_error: 20.0152 - val_loss: 24.3619 - val_mean_absolute_error: 24.3619\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 10.29650\n",
      "Epoch 441/500\n",
      "126/126 [==============================] - 0s 210us/step - loss: 20.5305 - mean_absolute_error: 20.5305 - val_loss: 22.9507 - val_mean_absolute_error: 22.9507\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 10.29650\n",
      "Epoch 442/500\n",
      "126/126 [==============================] - 0s 232us/step - loss: 20.2436 - mean_absolute_error: 20.2436 - val_loss: 22.5258 - val_mean_absolute_error: 22.5258\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 10.29650\n",
      "Epoch 443/500\n",
      "126/126 [==============================] - 0s 176us/step - loss: 19.7231 - mean_absolute_error: 19.7231 - val_loss: 16.5669 - val_mean_absolute_error: 16.5669\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 10.29650\n",
      "Epoch 444/500\n",
      "126/126 [==============================] - 0s 204us/step - loss: 21.0745 - mean_absolute_error: 21.0745 - val_loss: 19.5609 - val_mean_absolute_error: 19.5609\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 10.29650\n",
      "Epoch 445/500\n",
      "126/126 [==============================] - 0s 265us/step - loss: 19.9149 - mean_absolute_error: 19.9149 - val_loss: 20.4546 - val_mean_absolute_error: 20.4546\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 10.29650\n",
      "Epoch 446/500\n",
      "126/126 [==============================] - 0s 187us/step - loss: 20.3599 - mean_absolute_error: 20.3599 - val_loss: 20.8378 - val_mean_absolute_error: 20.8378\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 10.29650\n",
      "Epoch 447/500\n",
      "126/126 [==============================] - 0s 215us/step - loss: 19.9360 - mean_absolute_error: 19.9360 - val_loss: 20.6931 - val_mean_absolute_error: 20.6931\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 10.29650\n",
      "Epoch 448/500\n",
      "126/126 [==============================] - 0s 190us/step - loss: 20.4565 - mean_absolute_error: 20.4565 - val_loss: 17.5190 - val_mean_absolute_error: 17.5190\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 10.29650\n",
      "Epoch 449/500\n",
      "126/126 [==============================] - 0s 196us/step - loss: 20.7477 - mean_absolute_error: 20.7477 - val_loss: 25.5238 - val_mean_absolute_error: 25.5238\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 10.29650\n",
      "Epoch 450/500\n",
      "126/126 [==============================] - 0s 198us/step - loss: 20.3089 - mean_absolute_error: 20.3089 - val_loss: 21.1849 - val_mean_absolute_error: 21.1849\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 10.29650\n",
      "Epoch 451/500\n",
      "126/126 [==============================] - 0s 162us/step - loss: 19.6804 - mean_absolute_error: 19.6804 - val_loss: 18.5956 - val_mean_absolute_error: 18.5956\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 10.29650\n",
      "Epoch 452/500\n",
      "126/126 [==============================] - 0s 235us/step - loss: 20.0728 - mean_absolute_error: 20.0728 - val_loss: 19.1932 - val_mean_absolute_error: 19.1932\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 10.29650\n",
      "Epoch 453/500\n",
      "126/126 [==============================] - 0s 162us/step - loss: 19.6757 - mean_absolute_error: 19.6757 - val_loss: 23.4248 - val_mean_absolute_error: 23.4248\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 10.29650\n",
      "Epoch 454/500\n",
      "126/126 [==============================] - 0s 282us/step - loss: 19.7802 - mean_absolute_error: 19.7802 - val_loss: 22.1684 - val_mean_absolute_error: 22.1684\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 10.29650\n",
      "Epoch 455/500\n",
      "126/126 [==============================] - 0s 160us/step - loss: 20.0581 - mean_absolute_error: 20.0581 - val_loss: 26.6382 - val_mean_absolute_error: 26.6382\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 10.29650\n",
      "Epoch 456/500\n",
      "126/126 [==============================] - 0s 210us/step - loss: 20.8739 - mean_absolute_error: 20.8739 - val_loss: 16.6406 - val_mean_absolute_error: 16.6406\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 10.29650\n",
      "Epoch 457/500\n",
      "126/126 [==============================] - 0s 143us/step - loss: 21.3358 - mean_absolute_error: 21.3358 - val_loss: 16.6402 - val_mean_absolute_error: 16.6402\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 10.29650\n",
      "Epoch 458/500\n",
      "126/126 [==============================] - 0s 227us/step - loss: 20.9207 - mean_absolute_error: 20.9207 - val_loss: 29.4275 - val_mean_absolute_error: 29.4275\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 10.29650\n",
      "Epoch 459/500\n",
      "126/126 [==============================] - ETA: 0s - loss: 17.4723 - mean_absolute_error: 17.472 - 0s 160us/step - loss: 21.8947 - mean_absolute_error: 21.8947 - val_loss: 14.3756 - val_mean_absolute_error: 14.3756\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 10.29650\n",
      "Epoch 460/500\n",
      "126/126 [==============================] - 0s 149us/step - loss: 21.4816 - mean_absolute_error: 21.4816 - val_loss: 20.6106 - val_mean_absolute_error: 20.6106\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 10.29650\n",
      "Epoch 461/500\n",
      "126/126 [==============================] - 0s 184us/step - loss: 20.0175 - mean_absolute_error: 20.0175 - val_loss: 23.4010 - val_mean_absolute_error: 23.4010\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 10.29650\n",
      "Epoch 462/500\n",
      "126/126 [==============================] - 0s 148us/step - loss: 20.3623 - mean_absolute_error: 20.3623 - val_loss: 15.6350 - val_mean_absolute_error: 15.6350\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 10.29650\n",
      "Epoch 463/500\n",
      "126/126 [==============================] - ETA: 0s - loss: 22.4355 - mean_absolute_error: 22.435 - 0s 146us/step - loss: 21.9113 - mean_absolute_error: 21.9113 - val_loss: 29.5123 - val_mean_absolute_error: 29.5123\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 10.29650\n",
      "Epoch 464/500\n",
      "126/126 [==============================] - 0s 238us/step - loss: 22.1262 - mean_absolute_error: 22.1262 - val_loss: 21.3834 - val_mean_absolute_error: 21.3834\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 10.29650\n",
      "Epoch 465/500\n",
      "126/126 [==============================] - 0s 216us/step - loss: 23.1256 - mean_absolute_error: 23.1256 - val_loss: 13.2566 - val_mean_absolute_error: 13.2566\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 10.29650\n",
      "Epoch 466/500\n",
      "126/126 [==============================] - 0s 155us/step - loss: 22.3485 - mean_absolute_error: 22.3485 - val_loss: 29.4917 - val_mean_absolute_error: 29.4917\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 10.29650\n",
      "Epoch 467/500\n",
      "126/126 [==============================] - 0s 140us/step - loss: 21.6704 - mean_absolute_error: 21.6704 - val_loss: 19.4732 - val_mean_absolute_error: 19.4732\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 10.29650\n",
      "Epoch 468/500\n",
      "126/126 [==============================] - 0s 218us/step - loss: 20.4614 - mean_absolute_error: 20.4614 - val_loss: 16.9032 - val_mean_absolute_error: 16.9032\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 10.29650\n",
      "Epoch 469/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 0s 144us/step - loss: 21.0607 - mean_absolute_error: 21.0607 - val_loss: 23.7345 - val_mean_absolute_error: 23.7345\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 10.29650\n",
      "Epoch 470/500\n",
      "126/126 [==============================] - 0s 159us/step - loss: 20.2989 - mean_absolute_error: 20.2989 - val_loss: 19.3606 - val_mean_absolute_error: 19.3606\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 10.29650\n",
      "Epoch 471/500\n",
      "126/126 [==============================] - 0s 218us/step - loss: 19.8842 - mean_absolute_error: 19.8842 - val_loss: 17.9369 - val_mean_absolute_error: 17.9369\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 10.29650\n",
      "Epoch 472/500\n",
      "126/126 [==============================] - 0s 151us/step - loss: 19.8784 - mean_absolute_error: 19.8784 - val_loss: 22.5896 - val_mean_absolute_error: 22.5896\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 10.29650\n",
      "Epoch 473/500\n",
      "126/126 [==============================] - 0s 263us/step - loss: 20.3434 - mean_absolute_error: 20.3434 - val_loss: 25.0331 - val_mean_absolute_error: 25.0331\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 10.29650\n",
      "Epoch 474/500\n",
      "126/126 [==============================] - 0s 174us/step - loss: 20.2785 - mean_absolute_error: 20.2785 - val_loss: 22.1337 - val_mean_absolute_error: 22.1337\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 10.29650\n",
      "Epoch 475/500\n",
      "126/126 [==============================] - 0s 301us/step - loss: 19.6332 - mean_absolute_error: 19.6332 - val_loss: 21.9413 - val_mean_absolute_error: 21.9413\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 10.29650\n",
      "Epoch 476/500\n",
      "126/126 [==============================] - 0s 258us/step - loss: 20.1164 - mean_absolute_error: 20.1164 - val_loss: 21.9614 - val_mean_absolute_error: 21.9614\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 10.29650\n",
      "Epoch 477/500\n",
      "126/126 [==============================] - 0s 263us/step - loss: 19.7344 - mean_absolute_error: 19.7344 - val_loss: 18.8288 - val_mean_absolute_error: 18.8288\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 10.29650\n",
      "Epoch 478/500\n",
      "126/126 [==============================] - 0s 224us/step - loss: 19.8497 - mean_absolute_error: 19.8497 - val_loss: 17.2880 - val_mean_absolute_error: 17.2880\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 10.29650\n",
      "Epoch 479/500\n",
      "126/126 [==============================] - 0s 151us/step - loss: 19.7676 - mean_absolute_error: 19.7676 - val_loss: 30.3969 - val_mean_absolute_error: 30.3969\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 10.29650\n",
      "Epoch 480/500\n",
      "126/126 [==============================] - 0s 236us/step - loss: 20.7057 - mean_absolute_error: 20.7057 - val_loss: 19.9473 - val_mean_absolute_error: 19.9473\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 10.29650\n",
      "Epoch 481/500\n",
      "126/126 [==============================] - 0s 163us/step - loss: 20.0541 - mean_absolute_error: 20.0541 - val_loss: 23.0502 - val_mean_absolute_error: 23.0502\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 10.29650\n",
      "Epoch 482/500\n",
      "126/126 [==============================] - 0s 158us/step - loss: 19.6657 - mean_absolute_error: 19.6657 - val_loss: 22.6681 - val_mean_absolute_error: 22.6681\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 10.29650\n",
      "Epoch 483/500\n",
      "126/126 [==============================] - 0s 214us/step - loss: 19.9094 - mean_absolute_error: 19.9094 - val_loss: 22.5688 - val_mean_absolute_error: 22.5688\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 10.29650\n",
      "Epoch 484/500\n",
      "126/126 [==============================] - 0s 155us/step - loss: 19.5687 - mean_absolute_error: 19.5687 - val_loss: 23.3629 - val_mean_absolute_error: 23.3629\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 10.29650\n",
      "Epoch 485/500\n",
      "126/126 [==============================] - 0s 413us/step - loss: 19.3578 - mean_absolute_error: 19.3578 - val_loss: 24.2671 - val_mean_absolute_error: 24.2671\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 10.29650\n",
      "Epoch 486/500\n",
      "126/126 [==============================] - 0s 194us/step - loss: 19.4282 - mean_absolute_error: 19.4282 - val_loss: 18.8900 - val_mean_absolute_error: 18.8900\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 10.29650\n",
      "Epoch 487/500\n",
      "126/126 [==============================] - 0s 169us/step - loss: 19.7829 - mean_absolute_error: 19.7829 - val_loss: 23.9659 - val_mean_absolute_error: 23.9659\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 10.29650\n",
      "Epoch 488/500\n",
      "126/126 [==============================] - 0s 172us/step - loss: 20.1949 - mean_absolute_error: 20.1949 - val_loss: 26.5401 - val_mean_absolute_error: 26.5401\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 10.29650\n",
      "Epoch 489/500\n",
      "126/126 [==============================] - 0s 270us/step - loss: 21.4017 - mean_absolute_error: 21.4017 - val_loss: 19.9427 - val_mean_absolute_error: 19.9427\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 10.29650\n",
      "Epoch 490/500\n",
      "126/126 [==============================] - 0s 180us/step - loss: 20.7180 - mean_absolute_error: 20.7180 - val_loss: 16.8646 - val_mean_absolute_error: 16.8646\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 10.29650\n",
      "Epoch 491/500\n",
      "126/126 [==============================] - 0s 121us/step - loss: 20.5533 - mean_absolute_error: 20.5533 - val_loss: 25.1077 - val_mean_absolute_error: 25.1077\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 10.29650\n",
      "Epoch 492/500\n",
      "126/126 [==============================] - 0s 233us/step - loss: 21.4666 - mean_absolute_error: 21.4666 - val_loss: 26.1744 - val_mean_absolute_error: 26.1744\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 10.29650\n",
      "Epoch 493/500\n",
      "126/126 [==============================] - 0s 214us/step - loss: 20.7891 - mean_absolute_error: 20.7891 - val_loss: 22.0773 - val_mean_absolute_error: 22.0773\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 10.29650\n",
      "Epoch 494/500\n",
      "126/126 [==============================] - 0s 143us/step - loss: 20.4469 - mean_absolute_error: 20.4469 - val_loss: 18.3150 - val_mean_absolute_error: 18.3150\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 10.29650\n",
      "Epoch 495/500\n",
      "126/126 [==============================] - 0s 200us/step - loss: 19.9903 - mean_absolute_error: 19.9903 - val_loss: 22.2972 - val_mean_absolute_error: 22.2972\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 10.29650\n",
      "Epoch 496/500\n",
      "126/126 [==============================] - 0s 149us/step - loss: 21.8229 - mean_absolute_error: 21.8229 - val_loss: 30.9980 - val_mean_absolute_error: 30.9980\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 10.29650\n",
      "Epoch 497/500\n",
      "126/126 [==============================] - 0s 161us/step - loss: 21.1736 - mean_absolute_error: 21.1736 - val_loss: 14.4251 - val_mean_absolute_error: 14.4251\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 10.29650\n",
      "Epoch 498/500\n",
      "126/126 [==============================] - 0s 176us/step - loss: 22.1817 - mean_absolute_error: 22.1817 - val_loss: 23.3985 - val_mean_absolute_error: 23.3985\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 10.29650\n",
      "Epoch 499/500\n",
      "126/126 [==============================] - 0s 156us/step - loss: 21.0229 - mean_absolute_error: 21.0229 - val_loss: 29.4119 - val_mean_absolute_error: 29.4119\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 10.29650\n",
      "Epoch 500/500\n",
      "126/126 [==============================] - 0s 195us/step - loss: 23.1675 - mean_absolute_error: 23.1675 - val_loss: 12.5395 - val_mean_absolute_error: 12.5395\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 10.29650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1536dfafc88>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model.fit(df, target, epochs=500, batch_size=32, validation_split = 0.2, callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
